@misc{adetsuSensorBasedPeatThickness2023,
  type = {{{SSRN Scholarly Paper}}},
  title = {Sensor-{{Based Peat Thickness Mapping}} of a {{Cultivated Bog}} in {{Denmark}}},
  author = {Adetsu, Diana Vigah and Koganti, Triven and Greve, Mogens Humlekrog and Beucher, Am{\'e}lie M.},
  year = {2023},
  month = aug,
  number = {4535861},
  address = {Rochester, NY},
  doi = {10.2139/ssrn.4535861},
  urldate = {2024-04-24},
  abstract = {The unsustainable use of peatlands, mostly due to poor agricultural practices, has transformed many of the global peatland areas into carbon (C) sources and hotspots for greenhouse gas emissions. To mitigate such positive climate feedback, recent years have seen an increased interest in peatland restoration. An objective of peatland restoration programs is to monitor the spatiotemporal changes in the C-stock. Nevertheless, required information for peatland C-stock accounting such as the peat thickness (PT) is often lacking or available at lower than desired accuracy levels. While conventional methods for mapping PT are laborious and may be inaccurate, soil sensing techniques offer opportunities for more accurate and non-invasive mapping of soil properties. The present study aimed to assess the potency of three groups of sensory data obtained from a LiDAR-based digital elevation model (DEM), proximal electromagnetic induction (EMI) and gamma radiometric (GR) surveys, as covariates for the predictive mapping of PT of a 350-ha Danish bog. Seven multiple linear regression (MLR) and random forest (RF) models were built from the separate use of individual covariate groups, a combination of two groups and a combination of all three groups. The results indicated that models built with only proximally sensed EMI or GR covariates were the least accurate, especially for GR. Nevertheless, combining DEM and EMI covariates yielded the best prediction accuracy of PT for both MLR and RF models. For MLR, this resulted in an R2 and RMSE of 0.31 and 49.6 cm, and for RF, an R2 and RMSE of 0.61 and 37.3 cm. Overall, the present study demonstrates that for a bog with a long history of degradation induced by various land uses, covariates that characterize both surface and subsurface properties are essential for the predictive mapping of PT.},
  langid = {english},
  keywords = {degraded bog,digital soil mapping,electromagnetic induction,gamma ray,peat depth},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Adetsu et al. - 2023 - Sensor-Based Peat Thickness Mapping of a Cultivate.pdf}
}

@article{agrenDelineatingDistributionMineral2022a,
  title = {Delineating the Distribution of Mineral and Peat Soils at the Landscape Scale in Northern Boreal Regions},
  author = {{\AA}gren, Anneli M. and Hasselquist, Eliza Maher and Stendahl, Johan and Nilsson, Mats B. and Paul, Siddhartho S.},
  year = {2022},
  month = dec,
  journal = {SOIL},
  volume = {8},
  number = {2},
  pages = {733--749},
  publisher = {Copernicus GmbH},
  issn = {2199-3971},
  doi = {10.5194/soil-8-733-2022},
  urldate = {2024-08-15},
  abstract = {To meet the sustainable development goals and enable sustainable management and protection of peatlands, there is a strong need for improving the mapping of peatlands. Here we present a novel approach to identify peat soils based on a high-resolution digital soil moisture map that was produced by combining airborne laser scanning-derived terrain indices and machine learning to model soil moisture at 2 m spatial resolution across the Swedish landscape. As soil moisture is a key factor in peat formation, we fitted an empirical relationship between the thickness of the organic layer (measured at 5479 soil plots across the country) and the continuous SLU (Swedish University of Agricultural Science) soil moisture map (R2= 0.66, p \&lt; 0.001). We generated categorical maps of peat occurrence using three different definitions of peat (30, 40, and 50 cm thickness of the organic layer) and a continuous map of organic layer thickness. The predicted peat maps had a higher overall quality (MCC = 0.69--0.73) compared to traditional Quaternary deposits maps (MCC = 0.65) and topographical maps (MCC = 0.61) and captured the peatlands with a recall of ca. 80 \% compared to 50 \%--70 \% on the traditional maps. The predicted peat maps identified more peatland area than previous maps, and the areal coverage estimates fell within the same order as upscaling estimates from national field surveys. Our method was able to identify smaller peatlands resulting in more accurate maps of peat soils, which was not restricted to only large peatlands that can be visually detected from aerial imagery -- the historical approach of mapping. We also provided a continuous map of the organic layer, which ranged 6--88 cm organic layer thickness, with an R2 of 0.67 and RMSE (root mean square error) of 19 cm. The continuous map exhibits a smooth transition of organic layers from mineral soil to peat soils and likely provides a more natural representation of the distribution of soils. The continuous map also provides an intuitive uncertainty estimate in the delineation of peat soils, critically useful for sustainable spatial planning, e.g., greenhouse gas or biodiversity inventories and landscape ecological research.},
  langid = {english},
  keywords = {boreal,depth-to-water,mapping,peatland,To read},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary}
}

@misc{agrenDokumentationNyaTorvkartor2022,
  title = {{Dokumentation nya torvkartor -- klassade torvkartor och kontinuerliga kartor {\"o}ver organiska lagrets tjocklek}},
  author = {{\AA}gren, Anneli and Lin, Yiqi},
  year = {2022},
  month = dec,
  langid = {swedish},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Ågren - Dokumentation nya torvkartor – klassade torvkartor.pdf}
}

@article{agrenEvaluatingDigitalTerrain2014,
  title = {Evaluating Digital Terrain Indices for Soil Wetness Mapping -- a {{Swedish}} Case Study},
  author = {{\AA}gren, A. M. and Lidberg, W. and Str{\"o}mgren, M. and Ogilvie, J. and Arp, P. A.},
  year = {2014},
  month = sep,
  journal = {Hydrology and Earth System Sciences},
  volume = {18},
  number = {9},
  pages = {3623--3634},
  publisher = {Copernicus GmbH},
  issn = {1027-5606},
  doi = {10.5194/hess-18-3623-2014},
  urldate = {2024-04-11},
  langid = {english},
  keywords = {depth-to-water},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Ågren et al. - 2014 - Evaluating digital terrain indices for soil wetnes.pdf}
}

@article{agrenUseMultipleLIDARderived2021,
  title = {Use of Multiple {{LIDAR-derived}} Digital Terrain Indices and Machine Learning for High-Resolution National-Scale Soil Moisture Mapping of the {{Swedish}} Forest Landscape},
  author = {{\AA}gren, Anneli M. and Larson, Johannes and Paul, Siddhartho Shekhar and Laudon, Hjalmar and Lidberg, William},
  year = {2021},
  month = dec,
  journal = {Geoderma},
  volume = {404},
  pages = {115280},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2021.115280},
  urldate = {2024-08-15},
  abstract = {Spatially extensive high-resolution soil moisture mapping is valuable in practical forestry and land management, but challenging. Here we present a novel technique involving use of LIDAR-derived terrain indices and machine learning (ML) algorithms capable of accurately modeling soil moisture at 2~m spatial resolution across the entire Swedish forest landscape. We used field data from about 20,000 sites across Sweden to train and evaluate multiple ML models. The predictor features (variables) included a suite of terrain indices generated from a national LIDAR digital elevation model and ancillary environmental features, including surficial geology, climate and land use, enabling adjustment of soil moisture class maps to regional or local conditions. Extreme gradient boosting (XGBoost) provided better performance for a 2-class model, manifested by Cohen's Kappa and Matthews Correlation Coefficient (MCC) values of 0.69 and 0.68, respectively, than the other tested ML methods: Artificial Neural Network, Random Forest, Support Vector Machine, and Na{\"i}ve Bayes classification. The depth to water index, topographic wetness index, and `wetland' categorization derived from Swedish property maps were the most important predictors for all models. The presented technique enabled generation of a 3-class model with Cohen's Kappa and MCC values of 0.58. In addition to the classified moisture maps, we investigated the technique's potential for producing continuous soil moisture maps. We argue that the probability of a pixel being classified as wet from a 2-class model can be used as a 0--100\% index (dry to wet) of soil moisture, and the resulting maps could provide more valuable information for practical forest management than classified maps.},
  keywords = {Extreme gradient boosting,Land-use management,LIDAR,Machine learning,Soil moisture},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Ågren et al. - 2021 - Use of multiple LIDAR-derived digital terrain indi.pdf}
}

@article{arrouaysImpressionsDigitalSoil2020,
  title = {Impressions of Digital Soil Maps: {{The}} Good, the Not so Good, and Making Them Ever Better},
  shorttitle = {Impressions of Digital Soil Maps},
  author = {Arrouays, Dominique and McBratney, Alex and Bouma, Johan and Libohova, Zamir and {Richer-de-Forges}, Anne C. and Morgan, Cristine L. S. and Roudier, Pierre and Poggio, Laura and Mulder, Vera Leatitia},
  year = {2020},
  month = mar,
  journal = {Geoderma Regional},
  volume = {20},
  pages = {e00255},
  issn = {2352-0094},
  doi = {10.1016/j.geodrs.2020.e00255},
  urldate = {2024-01-30},
  abstract = {Since the turn of the millennium, digital soil mapping (DSM) has revolutionized the production of fine resolution gridded soil data with associated uncertainty. However, the link to conventional soil maps has not been sufficiently explained nor are the approaches complementary and synergistic. Further training on the digital soil mapping approaches, and associated strengths and weaknesses is required. The user community requires training in, and experience with, the new digital soil map products, especially about the use of uncertainties for risk modelling and policy development. Standards are required for public and private sector digital soil map products to prevent the production of poor-quality information which will become misleading and counter-productive. Machine-learning methods are to be used with caution with respect to their interpretability and parsimony. The use of DSM products for improved pedological understanding and soil survey interpretations requires urgent investigation.},
  keywords = {Digital soil assessment,Digital soil mapping,Machine learning,Pedology,Soil survey},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Arrouays et al. - 2020 - Impressions of digital soil maps The good, the no.pdf}
}

@techreport{baranwalHelicopterborneMagneticElectromagnetic2013,
  title = {Helicopter-Borne Magnetic, Electromagnetic and Radiometric Geophysical Surveys in the {{Kongsberg}} Region: {{Kr{\o}deren}}, {{Sokna}}, {{H{\o}nef{\o}ss}}, {{Kongsberg}} and {{Numedalen}}.},
  author = {Baranwal, Vikas and Rodionov, Alexei and Ofstad, Frode and Koziel, Janusz and Lynum, Rolf},
  year = {2013},
  number = {2013.029},
  institution = {Geological Survey of Norway},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Baranwal et al. - 2013 - Helicopter-borne magnetic, electromagnetic and rad.pdf}
}

@article{beamishAirborneGeophysicsNovel2013,
  title = {Airborne Geophysics: A Novel Approach to Assist Hydrogeological Investigations at Groundwater-Dependent Wetlands},
  shorttitle = {Airborne Geophysics},
  author = {Beamish, David and Farr, Gareth},
  year = {2013},
  month = feb,
  journal = {Quarterly Journal of Engineering Geology and Hydrogeology},
  volume = {46},
  number = {1},
  pages = {53--62},
  publisher = {The Geological Society of London},
  doi = {10.1144/qjegh2012-019},
  urldate = {2024-09-12},
  abstract = {This paper provides an assessment of existing airborne baseline geophysical data in relation to the hydrogeological characterization of protected groundwater-dependent terrestrial ecosystems (wetlands) in Anglesey, Wales. The attenuation of the radiometric data identifies the main areas of water saturation in the very near surface. The radiometric data have the potential to identify additional areas where similar degrees of saturation exist. The data may therefore be used to help define extensions to existing site boundaries and to provide information in the assessment of new wetland areas. The radiometric data also show regional-scale transition from the Carboniferous Limestone in the east, important for water supply to the wetlands, to older more impermeable strata to the west. The conductivity data appear capable of mapping the lateral extent of clay accumulations, concealed below peat cover which can act as a confining layer to the bedrock aquifer. At the regional scale the data reveal the extent of a former Holocene lake system and the hydrogeological control of a Carboniferous limestone--sandstone contact. The data therefore provide a non-invasive spatially continuous, characterization of the sites, improving the understanding of their dynamic water balances and, potentially, guiding further ground assessments and invasive investigations.},
  file = {C:\Users\julienv\Zotero\storage\63UZGRKT\Beamish and Farr - 2013 - Airborne geophysics a novel approach to assist hy.pdf}
}

@article{beamishDetailedMappingPeat2024,
  title = {On the Detailed Mapping of Peat (Raised Bogs) Using Airborne Radiometric Data},
  author = {Beamish, David and White, James C.},
  year = {2024},
  month = jul,
  journal = {Journal of Environmental Radioactivity},
  volume = {277},
  pages = {107462},
  issn = {0265-931X},
  doi = {10.1016/j.jenvrad.2024.107462},
  urldate = {2024-07-04},
  abstract = {This study concerns the applied use of the natural radioactivity in soils. The relevance of airborne radiometric (gamma ray) survey data to peat mapping is now well established and such data have been used in a stand-alone sense and as covariates in machine learning algorithms. Here we present a method to use these data to accurately map the boundaries of peat (raised bogs). This has the potential to assist with the estimation of carbon stocks using a property-based assessment of soil. The significance of such regionally-uniform survey data lies in the subsurface information carried by the measurement which contrasts with the surficial nature of many other covariates. Soils attenuate radiometric flux by virtue of their bulk density (and associated carbon content) and water saturation level. The high attenuation levels in low density, wet peat materials give rise to a distinctive soil response. Here an entirely physics-based assessment of flux attenuation is carried out both theoretically and empirically. Radiometric data from the ongoing Tellus airborne survey of Ireland are used. The study area is characterised by an extensive assemblage of discrete raised peat bogs in a framework of largely mineral soils. Peat is detected by a property contrast with adjacent soils and so we consider all soils within the study area. The relatively low lateral resolution of the airborne data is demonstrated by modelling and we examine the behaviour of a combined spatial derivative of the data. The procedure allows the identification of the edges of the 128 peat polygons considered and indicates other additional potential areas of subsurface peat. The data appear to resolve the differences that exist across three available soil/peat databases that are used for the validation of the results obtained.},
  keywords = {Airborne,Attenuation,Geophysics,Peat mapping,Radiometric,Soil bulk density,To read},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Beamish and White - 2024 - On the detailed mapping of peat (raised bogs) usin.pdf}
}

@article{beamishEnhancingResolutionAirborne2016,
  title = {Enhancing the Resolution of Airborne Gamma-Ray Data Using Horizontal Gradients},
  author = {Beamish, David},
  year = {2016},
  month = sep,
  journal = {Journal of Applied Geophysics},
  volume = {132},
  pages = {75--86},
  issn = {0926-9851},
  doi = {10.1016/j.jappgeo.2016.07.006},
  urldate = {2024-07-04},
  abstract = {The spatial resolution characteristics of airborne gamma-ray data are largely controlled by survey elevation and line separation. In the UK, although low nominal surveys altitudes may be permitted, regulatory zones with elevations in excess of 180m are required above conurbations. Since the data, typically in the form of grids, are evaluated alongside many other detailed geoscientific spatial datasets their absolute resolution limits, together with their spatial characteristics, become relevant. Here, using published software, we study the theoretical resolution characteristics of this form of survey data obtained with a line separation of 200m. Of particular interest is the airborne response behaviour when non-uniform distributions of radioactivity are encountered. Although ultimately a function of the radioelement-concentration contrast encountered, the calculations reveal that such zones are most difficult to identify when their scale length decreases below the scale of the line separation. This limited resolution then further decreases with elevation. In order to increase our ability to resolve the edges of non-uniform source regions we calculate the horizontal gradient magnitude (HGM) of the observed data. While the data used can be the estimated radioelement concentrations (potassium, thorium and uranium) or their ratios, we demonstrate that the total count is particularly suited to this type of analysis. The theoretical calculations are supported by an examination of survey data across a series of isolated bodies (offshore islands). This empirical study indicates the practical limits to resolution when using the horizontal gradient and these are governed by the survey line separation. The HGM response provides an enhanced mapping of the edges of zones associated with a contrast in flux behaviour. The edges are detected using the maxima in the response and these can be additionally examined using grid curvature analysis. The technique is assessed using recent survey data containing geological, soil and environmental influences. The results demonstrate the spatially pervasive nature of flux contrasts associated with soil and environmental contributions which potentially mask, or perturb, the underlying bedrock geological response.},
  keywords = {Airborne gamma-ray data,Data processing,Geology,Horizontal gradient,Soil},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Beamish - 2016 - Enhancing the resolution of airborne gamma-ray dat.pdf}
}

@article{beamishGammaRayAttenuation2013,
  title = {Gamma Ray Attenuation in the Soils of {{Northern Ireland}}, with Special Reference to Peat},
  author = {Beamish, David},
  year = {2013},
  month = jan,
  journal = {Journal of Environmental Radioactivity},
  volume = {115},
  pages = {13--27},
  issn = {0265-931X},
  doi = {10.1016/j.jenvrad.2012.05.031},
  urldate = {2024-07-04},
  abstract = {This study considers gamma ray attenuation in relation to the soils and bedrock of Northern Ireland using simple theory and data from a high resolution airborne survey. The bedrock is considered as a source of radiogenic material acting as parent to the soil. Attenuation in the near-surface is then controlled by water content in conjunction with the porosity and density of the soil cover. The Total Count radiometric data together with 1:250~k mapping of the soils and bedrock of Northern Ireland are used to perform statistical analyses emphasising the nature of the low count behaviour. Estimations of the bedrock response characteristics are improved by excluding areas covered by low count soils (organic/humic). Equally, estimations of soil response characteristics are improved by excluding areas underlain by low count bedrock (basalt). When the spatial characteristics of the soil-classified data are examined in detail, the low values form spatially-coherent zones (natural clusters) that can potentially be interpreted as areas of increased water content for each soil type. As predicted by theory, the highest attenuation factors are associated with the three organic soil types studied here. Peat, in particular, is remarkably skewed to low count behaviour in its radiometric response. Two detailed studies of blanket bogs reveal the extent to which peat may be mapped by its radiometric response while the intra-peat variations in the observed response may indicate areas of thin cover together with areas of increased water content.},
  keywords = {Airborne,Attenuation,Gamma-ray,Moisture,Peat,Soil},
  file = {C:\Users\julienv\Zotero\storage\7PDPCJFH\Beamish - 2013 - Gamma ray attenuation in the soils of Northern Ire.pdf}
}

@article{beamishPeatMappingAssociations2014,
  title = {Peat {{Mapping Associations}} of {{Airborne Radiometric Survey Data}}},
  author = {Beamish, David},
  year = {2014},
  month = jan,
  journal = {Remote Sensing},
  volume = {6},
  number = {1},
  pages = {521--539},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs6010521},
  urldate = {2024-07-04},
  abstract = {This study considers recent airborne radiometric (gamma ray) survey data, obtained at high-resolution, across various regions of the UK. The datasets all display a very evident attenuation of signal in association with peat, and intra-peat variations are observed. The geophysical response variations are examined in detail using example data sets across lowland areas (raised bogs, meres, fens and afforested peat) and upland areas of blanket bog, together with associated wetland zones. The radiometric data do not map soils per se. The bedrock (the radiogenic parent) provides a specific amplitude level. Attenuation of this signal level is then controlled by moisture content in conjunction with the density and porosity of the soil cover. Both soil and bedrock variations need to be jointly assessed. The attenuation theory, reviewed here, predicts that the behaviour of wet peat is distinct from most other soil types. Theory also predicts that the attenuation levels observed across wet peatlands cannot be generally used to map variations in peat thickness. Four survey areas at various scales, across England, Scotland, Wales and Ireland are used to demonstrate the ability of the airborne data to map peat zones. A 1:50 k national mapping of deep peat is used to provide control although variability in the definition of peat zones across existing databases is also demonstrated.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {airborne geophysical,mapping,peat,radiometric,remote sensing,wetland},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Beamish - 2014 - Peat Mapping Associations of Airborne Radiometric .pdf}
}

@article{beamishRelationshipsGammarayAttenuation2015,
  title = {Relationships between Gamma-Ray Attenuation and Soils in {{SW England}}},
  author = {Beamish, David},
  year = {2015},
  month = dec,
  journal = {Geoderma},
  volume = {259--260},
  pages = {174--186},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2015.05.018},
  urldate = {2024-07-04},
  abstract = {Soil studies using radiometric data typically employ one or more of the main, naturally occurring radioelement estimates (potassium, thorium and uranium) to undertake a variety of soil property assessments. This study concerns an attenuation assessment of high-resolution radiometric data obtained by a recent airborne geophysical survey in SW England. These data provide continuous measurements over a wide-range of region-specific soils and their parent bedrock materials. A prime motivation for this study is the observed complexity of the spatial variance in the radiometric signal level. Although such data may be jointly classified according to soil and bedrock types, variable attenuation levels in the signal levels remain to be explained. The data appear to carry information on soil properties additional to that of texture or other available soil descriptors. Existing gamma-ray theory indicates that the attenuation behaviour of radiometric data is jointly controlled by soil density and wetness in the upper {\textasciitilde}60cm of the soil profile. Low density, highly organic soils (e.g. peat) produce readily identifiable and variable attenuation zones. All soil types are predicted to attenuate radiometric signal levels but at lower density--wetness sensitivities. The broad radiometric response level is, as expected, found to be controlled by bedrock. Clay mineral soils provide the most uniform response behaviour with respect to bedrock type. Peat soils display the lowest amplitude and most variable signal levels. The data from similar bedrock formations, even with the same lithological descriptor (e.g. argillaceous), can display distinctly different geostatistical behaviour when the same soil type is considered. A variety of inferred attenuation zones are discussed in relation to supporting information on soil property and soil and land-use classifications. Spatial inconsistencies in existing database descriptors of organic rich zones are demonstrated and it is evident that the radiometric data can assist in resolving such ambiguities. The supporting control information has been found to be often ambiguous or unavailable at a scale appropriate to the field-of-view of the airborne measurements. Within this wider context, it is suggested that an observational database, such as that supplied by the radiometric data, may assist in providing enhanced spatial assessments of the soils and soil properties encountered},
  keywords = {Airborne,Bedrock,Gamma-ray,Radiometric,Soil,UK},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Beamish - 2015 - Relationships between gamma-ray attenuation and so.pdf}
}

@article{beguinPredictingSoilProperties2017,
  title = {Predicting Soil Properties in the {{Canadian}} Boreal Forest with Limited Data: {{Comparison}} of Spatial and Non-Spatial Statistical Approaches},
  shorttitle = {Predicting Soil Properties in the {{Canadian}} Boreal Forest with Limited Data},
  author = {Beguin, Julien and Fuglstad, Geir-Arne and Mansuy, Nicolas and Par{\'e}, David},
  year = {2017},
  month = nov,
  journal = {Geoderma},
  volume = {306},
  pages = {195--205},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2017.06.016},
  urldate = {2023-06-12},
  abstract = {Digital soil mapping (DSM) involves the use of georeferenced information and statistical models to map predictions and uncertainties related to soil properties. Many remote regions of the globe, such as boreal forest ecosystems, are characterized by low sampling efforts and limited availability of field soil data. Although DSM is an expanding topic in soil science, little guidance currently exists to select the appropriate combination of statistical methods and model formulation in the context of limited data availability. Using the Canadian managed forest as a case study, the main objective of this study was to investigate to which extent the choice of statistical method and model specification could improve the spatial prediction of soil properties with limited data. More specifically, we compared the cross-product performance of eight statistical approaches (linear, additive and geostatistical models, and four machine-learning techniques) and three model formulations (``covariates only'': a suite of environmental covariates only; ``spatial only'': a function of geographic coordinates only; and ``covariates+spatial'': a combination of both covariates and spatial functions) to predict five key forest soil properties in the organic layer (thickness and C:N ratio) and in the top 15cm of the mineral horizon (carbon concentration, percentage of sand, and bulk density). Our results show that 1) although strong differences in predictive performance occurred across all statistical approaches and model formulations, spatially explicit models consistently had higher R2 and lower RMSE values than non-spatial models for all soil properties, except for the C:N ratio; 2) Bayesian geostatistical models were among the best methods, followed by ordinary kriging and machine-learning methods; and 3) comparative analyses made it possible to identify the more performant models and statistical methods to predict specific soil properties. We make modeling tools and code available (e.g., Bayesian geostastical models) that increase DSM capabilities and support existing efforts toward the production of improved digital soil products with limited data.},
  langid = {english},
  keywords = {Bayesian,boosted regression tree,digital soil mapping,forest,kriging,ML,RF,SAC,To read},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Beguin et al. - 2017 - Predicting soil properties in the Canadian boreal .pdf}
}

@article{bohnLocallyEnhancedDigital2024,
  title = {Locally Enhanced Digital Soil Mapping in Support of a Bottom-up Approach Is More Accurate than Conventional Soil Mapping and Top-down Digital Soil Mapping},
  author = {Bohn, Meyer P. and Miller, Bradley A.},
  year = {2024},
  month = feb,
  journal = {Geoderma},
  volume = {442},
  pages = {116781},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2024.116781},
  urldate = {2024-01-30},
  abstract = {This study presents a regional digital soil mapping (DSM) product that used a locally enhanced method in support of a bottom-up approach to create spatial soil predictions that were more accurate than one of the most accurate and detailed conventional soil mapping (CSM) products in the world, the Soil Survey Geographic (SSURGO) map from the United States Department of Agriculture, Natural Resources Conservation Service. Prior to this work, DSM products had yet to definitively outperform CSM products, except in locations where existing CSM maps were based on low investment (e.g., generalized national soil maps). While DSM has had established advantages, such as quantitative property prediction and cost efficiency, remaining challenges for widespread adoption include obtaining accuracy and practicality that exceed CSM-based maps in areas with histories of strong soil survey programs. In comparison with SSURGO, multiple top-down DSM products (SoilGrids 2.0, POLARIS, and Soil Properties and Class 100~m Grids of the USA) were evaluated along with the locally enhanced DSM product called LE-DSM (locally enhanced digital soil map). These maps were compared for their predictions of clay, silt, sand, and organic matter content at standard depth intervals to 200~cm. SSURGO outperformed the national and global top-down DSM products for 75~\% of the soil properties and depths. In contrast, LE-DSM demonstrated appreciably higher accuracy than SSURGO 46~\% of the time. These results indicate that bottom-up DSM products are needed for superseding the accuracy of CSM products, which themselves are constructed from a locally enhanced bottom-up approach.},
  keywords = {digital soil mapping,Locally enhanced model,Map comparison},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Bohn and Miller - 2024 - Locally enhanced digital soil mapping in support o.pdf}
}

@article{brusSamplingDigitalSoil2019,
  title = {Sampling for Digital Soil Mapping: {{A}} Tutorial Supported by {{R}} Scripts},
  shorttitle = {Sampling for Digital Soil Mapping},
  author = {Brus, D. J.},
  year = {2019},
  month = mar,
  journal = {Geoderma},
  volume = {338},
  pages = {464--480},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2018.07.036},
  urldate = {2023-06-21},
  abstract = {In the past decade, substantial progress has been made in model-based optimization of sampling designs for mapping. This paper is an update of the overview of sampling designs for mapping presented by de Gruijter et al. (2006). For model-based estimation of values at unobserved points (mapping), probability sampling is not required, which opens up the possibility of optimized non-probability sampling. Non-probability sampling designs for mapping are regular grid sampling, spatial coverage sampling, k-means sampling, conditioned Latin hypercube sampling, response surface sampling, Kennard-Stone sampling and model-based sampling. In model-based sampling a preliminary model of the spatial variation of the soil variable of interest is used for optimizing the sample size and or the spatial coordinates of the sampling locations. Kriging requires knowledge of the variogram. Sampling designs for variogram estimation are nested sampling, independent random sampling of pairs of points, and model-based designs in which either the uncertainty about the variogram parameters, or the uncertainty about the kriging variance is minimized. Various minimization criteria have been proposed for designing a single sample that is suitable both for estimating the variogram and for mapping. For map validation, additional probability sampling is recommended, so that unbiased estimates of map quality indices and their standard errors can be obtained. For all sampling designs, R scripts are available in the supplement. Further research is recommended on sampling designs for mapping with machine learning techniques, designs that are robust against deviations of modeling assumptions, designs tailored at mapping multiple soil variables of interest and soil classes or fuzzy memberships, and probability sampling designs that are efficient both for design-based estimation of populations means and for model-based mapping.},
  langid = {english},
  keywords = {fieldwork,K-means sampling,Kriging,Latin hypercube sampling,Model-based sampling,Spatial coverage sampling,Spatial simulated annealing,Variogram},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Brus - 2019 - Sampling for digital soil mapping A tutorial supp.pdf}
}

@article{deragonMappingMaximumPeat2023,
  title = {Mapping the Maximum Peat Thickness of Cultivated Organic Soils in the Southwest Plain of {{Montreal}}},
  author = {Deragon, Rapha{\"e}l and Saurette, Daniel D. and Heung, Brandon and Caron, Jean},
  year = {2023},
  journal = {Canadian Journal of Soil Science},
  volume = {103},
  pages = {103--120},
  publisher = {NRC Research Press},
  issn = {0008-4271},
  doi = {10.1139/cjss-2022-0031},
  urldate = {2023-02-09},
  abstract = {Large organic deposits in the southwestern plain of Montreal have been converted to agricultural land for vegetable production. In addition to the variable depth of the organic deposits, these soils commonly have an impermeable coprogenous layer between the peat and the underlying mineral substratum. Estimations of the depth and thickness of these materials are critical for soil management. Therefore, five drained and cultivated peatlands were studied to estimate their maximum peat thickness (MPT)---a potential key soil property that can help identify management zones for their conservation. MPT can be defined as the depth to the mineral layer (DML) minus the coprogenous layer thickness (CLT). The objective of this study was to estimate DML, CLT, and MPT at a regional scale using environmental covariates derived from remote sensing. Three machine-learning models (Cubist, Random Forest, and k-Nearest Neighbor) were compared to produce maps of DML and CLT, which were combined to generate MPT at a spatial resolution of 10~m. The Cubist model performed the best for predicting both features of interest, yielding Lin's concordance correlation coefficients of 0.43 and 0.07 for DML and CLT, respectively, using a spatial cross-validation procedure. Interpretation of the drivers of CLT was limited by the poor predictive power of the final model. More precise data on MPT are needed to support soil conservation practices, and more CLT field observations are required to obtain a higher prediction accuracy. Nonetheless, digital soil mapping using open-access geospatial data shows promise for understanding and managing cultivated peatlands.},
  keywords = {digital soil mapping,machine learning,peatland,remote sensing,SAC,soil,To read},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Deragon et al. - 2022 - Mapping the maximum peat thickness of cultivated o.pdf}
}

@misc{DroneborneGammarayMapping,
  title = {Towards Drone-Borne Gammaray Mapping of Soils},
  urldate = {2024-04-25},
  abstract = {ST Limburg.pdf Han Limburg1*, Steven van der Veeke1 and Ronald Koomans1 discuss the latest thinking on spectral gamma-ray technology for use in dro...},
  howpublished = {https://the.medusa.institute/wiki/towards-drone-borne-gammaray-mapping-of-soils},
  langid = {english}
}

@article{dumontOperationalSamplingDesigns2024,
  title = {Operational Sampling Designs for Poorly Accessible Areas Based on a Multi-Objective Optimization Method},
  author = {Dumont, Maxime and Brunel, Guilhem and Tresson, Paul and Nespoulous, J{\'e}r{\^o}me and Boukcim, Hassan and Ducousso, Marc and Boivin, St{\'e}phane and Taugourdeau, Olivier and Tisseyre, Bruno},
  year = {2024},
  month = may,
  journal = {Geoderma},
  volume = {445},
  pages = {116888},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2024.116888},
  urldate = {2024-04-25},
  abstract = {Sampling for Digital Soil Mapping is an expensive and time-constrained operation. It is crucial to consider these limitations in practical situations, particularly when dealing with large-scale areas that are remote and poorly accessible. To address this issue, several authors have proposed methods based on cost constraints optimization to reduce the travel time between sampling sites. These methods focused on optimizing the access cost associated to each sample site, but have not explicitly addressed field work time required for the whole sampling campaign. Hence, an estimation of fieldwork time is of great interest to assists soil surveyors in efficiently planning and executing optimized field surveys. The goal of this study is to propose, implement and test a new method named Multi-Objective Operational Sampling (MOOS), to minimize sampling route time, while ensuring that sample representativeness of the area is maintained. It offers multiple optimal sampling designs, allowing practitioners to select the most suitable option based on their desired sample quality and available time resources. The proposed sampling method is derived from conditioned Latin Hypercube sampling (cLHS) that optimizes both total field work time (travel time and on-site sampling time) and sample representativeness of the study area (cLHS objective function). The use of a multi-objective optimization algorithm (NSGA II) provides a variety of optimal sampling designs with varying sample size. The sampling route time computation is based on an access cost map derived from remote sensing images and expert annotation data. A least-cost algorithm is used to create a time matrix allowing precise evaluation of the time required to connect each pair of sites and thus determine an optimal path. The proposed method has been implemented and tested on sampling for pHH2O mapping within a 651 points kilometric grid in the northern part of Saudi Arabia, where soil analyses were conducted over a 1,069~km2 area. MOOS method was compared to two other common approaches: classical cLHS and cLHS incorporating access cost. The performance of each method was assessed with the cross-validated RMSE and sampling route time in days. Results show that the MOOS method outperforms the two others in terms of sampling route time, especially with increasing sample size, gaining up to 1~day of work for the presented case study. It still ensures a relevant map accuracy and sample representativeness when compared to the two methods. This approach yields promising outcomes for field sampling in digital soil mapping. By simultaneously optimizing both sample representativeness and cost constraints, it holds potential as a valuable decision support tool for soil surveyors facing sampling designs in poorly accessible areas.},
  keywords = {cLHS,Digital Soil Mapping,Field constraints,Pareto optimality,sampling design,Soil sampling,To read,traveling salesman problem}
}

@article{endrestolPrincipleMethodMeasurement1980,
  title = {Principle and Method for Measurement of Snow Water Equivalent by Detection of Natural Gamma Radiation / {{Principe}} et M{\'e}thode Pour La Mesure de l'hauteur d'eau {\'E}quivalente Par D{\'e}tection Du Rayonnement Gamma Naturel},
  author = {Endrest{\o}l, Guttorm O},
  year = {1980},
  month = mar,
  journal = {Hydrological Sciences Bulletin},
  volume = {25},
  number = {1},
  pages = {77--83},
  publisher = {Taylor \& Francis},
  issn = {0303-6936},
  doi = {10.1080/02626668009491906},
  urldate = {2024-08-15},
  abstract = {The principles of snow cover determination by use of terrestrial gamma radiation are presented. Several proposed methods of measurement are discussed and some of the more important sources of error for these methods are listed. Finally the accuracies of the methods are estimated.},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\ENDRESTØL - 1980 - Principle and method for measurement of snow water.pdf}
}

@book{erdi-krauszGuidelinesRadioelementMapping2003,
  title = {Guidelines for Radioelement Mapping Using Gamma Ray Spectrometry Data},
  shorttitle = {Guidelines for Radioelement Mapping Using Gamma Ray Spectrometry Data},
  author = {{Erdi-Krausz}, G. and Matolin, M. and Minty, B. and Nicolet, J. P. and Reford, W. S. and Schetselaar, E. M.},
  year = {2003},
  publisher = {International Atomic Energy Agency (IAEA)},
  urldate = {2021-01-29},
  isbn = {978-92-0-108303-6},
  langid = {english},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Erdi-Krausz et al_2003_Guidelines for radioelement mapping using gamma ray spectrometry data.pdf}
}

@article{fanDigitalSoilMapping2022,
  title = {Digital Soil Mapping with Adaptive Consideration of the Applicability of Environmental Covariates over Large Areas},
  author = {Fan, Nai-Qing and Zhao, Fang-He and Zhu, Liang-Jun and Qin, Cheng-Zhi and Zhu, A-Xing},
  year = {2022},
  month = sep,
  journal = {International Journal of Applied Earth Observation and Geoinformation},
  volume = {113},
  pages = {102986},
  issn = {1569-8432},
  doi = {10.1016/j.jag.2022.102986},
  urldate = {2023-06-12},
  abstract = {The effective use of environmental covariates in characterizing soil--environment relationships is key to successful digital soil mapping. The typical way to use environmental covariates in digital soil mapping is by selecting diverse environmental covariates considering the overall geographical characteristics of the study area and considering these covariates to have consistent applicability across the whole area. However, this practice ignores the fact that the applicability of each environmental covariate in characterizing soil--environment relationships varies over complex environmental conditions, especially in large areas. This study proposed a method to adaptively consider covariate applicability in large-area digital soil mapping using soil--environment relationships. The applicability of each covariate at each location was quantified from the terrain conditions using the newly designed fuzzy functions in the study. Then the covariate applicability was regarded as the importance weight and integrated into an existing representative method, iPSM (individual predictive soil mapping). The integration was separately performed at the similarity calculation and soil estimation stages of iPSM to generate two new methods: iPSM weighting on the applicability of all covariates (iPSM\_WCovar\_all), and iPSM weighting on the applicability of the limiting covariate (i.e., the covariate with the minimum similarity between two locations that constrains the overall similarity) (iPSM\_WCovar\_limit). Experiments were carried in Anhui Province, China. The two new methods were used to predict the soil organic matter content of topsoil and outperformed the original iPSM and random forest kriging methods. The root mean square error of the iPSM\_WCovar\_all, iPSM\_WCovar\_limit, iPSM and random forest kriging methods were 8.14, 8.00, 8.88 and 9.65~g/kg, respectively, while the mean absolute error of those methods were 6.48, 6.31, 6.61 and 6.82~g/kg. Both proposed methods outperformed the iPSM method and the other commonly used method, i.e., random forest kriging. Moreover, the performance was stable under different parameter settings. Experimental results indicate that the idea of adaptively considering covariate applicability in digital soil mapping is feasible and effective.},
  langid = {english},
  keywords = {Covariates applicability,Digital soil mapping,Individual predictive soil mapping (iPSM),Large area,Soil-environment relationship,Uncertainty},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Fan et al. - 2022 - Digital soil mapping with adaptive consideration o.pdf}
}

@article{fiantisMappingPeatThickness2023,
  title = {Mapping Peat Thickness and Carbon Stock of a Degraded Peatland in {{West Sumatra}}, {{Indonesia}}},
  author = {Fiantis, Dian and {Rudiyanto} and Ginting, Frisa Irawan and Agtalarik, Aldo and Arianto, Destri Tito and Wichaksono, Panji and Irfan, Rahmad and Nelson, Malik and Gusnidar, Gusnidar and Jeon, Sangho and Minasny, Budiman},
  year = {2023},
  journal = {Soil Use and Management},
  volume = {n/a},
  number = {n/a},
  issn = {1475-2743},
  doi = {10.1111/sum.12954},
  urldate = {2023-09-05},
  abstract = {Tropical peatlands store a large amount of carbon and act as carbon sinks, thus have crucial roles in regulating climate by preventing CO2 emission and enhancing carbon sequestration. However, the conversion of these peatlands for agricultural purposes, such as oil palm plantations, leads to carbon loss and increased CO2 emissions. To effectively protect and manage vulnerable areas, accurate mapping of peatland thickness and carbon stocks is essential, aligning with Indonesia's National Determined Contribution to climate action. This research article aims to assess the status of peatland in Agam-West Pasaman, Western Sumatra, which was cleared between 1990 and 2000 for oil palm cultivation. Digital Soil Mapping (DSM) approaches were employed to map peat thickness, carbon stock and estimate carbon loss resulting from land use change. The study area, spanning 54,000 hectares, was covered by peat-swamp forest in 1989. A grid of 2 km was used for a soil survey, resulting in 134 observation points of peat thickness, water level and subsidence. Various spatial prediction methods, including geostatistics, machine learning (ML) and their combination, were tested to map peat thickness, carbon stocks, subsidence rate and carbon loss. The covariates considered in the analysis were elevation, nearest distance from rivers and Sentinel 1a radar images. The results obtained through 10-fold cross-validations revealed that ordinary kriging exhibited the best performance, with an R2 of 0.44 for peat thickness and 0.39 for carbon stocks. The superior performance of ordinary kriging can be attributed to the severe impact of human activities in the area, which disrupted the clear relationship between peat parameters and environmental covariates. The estimated carbon stock of the area was 107 Mt C (std. dev. 0.143 Mt), while the carbon loss since the establishment of oil palm plantations was estimated to be 19.50 Mt C (std. dev. 0.017 Mt C) based on subsidence data. These findings provide insights into the degradation of the peatland and the magnitude of carbon loss over the past three decades. This information supports informed decision-making and contributes to efforts aimed at preserving and restoring peatlands.},
  copyright = {{\copyright} 2023 The Authors. Soil Use and Management published by John Wiley \& Sons Ltd on behalf of British Society of Soil Science.},
  langid = {english},
  keywords = {carbon stock,climate change,digital soil mapping,kriging,LUC,peatland,To read,tropical},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Fiantis et al. - Mapping peat thickness and carbon stock of a degra.pdf}
}

@article{florinskyIllustratedIntroductionGeneral2017,
  title = {An Illustrated Introduction to General Geomorphometry},
  author = {Florinsky, Igor V},
  year = {2017},
  month = dec,
  journal = {Progress in Physical Geography: Earth and Environment},
  volume = {41},
  number = {6},
  pages = {723--752},
  publisher = {SAGE Publications Ltd},
  issn = {0309-1333},
  doi = {10.1177/0309133317733667},
  urldate = {2024-04-11},
  langid = {english},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Florinsky - 2017 - An illustrated introduction to general geomorphome.pdf}
}

@article{gallantMultiresolutionIndexValley2003,
  title = {A Multiresolution Index of Valley Bottom Flatness for Mapping Depositional Areas},
  author = {Gallant, John C. and Dowling, Trevor I.},
  year = {2003},
  journal = {Water Resources Research},
  volume = {39},
  number = {12},
  issn = {1944-7973},
  doi = {10.1029/2002WR001426},
  urldate = {2023-04-18},
  abstract = {Valley bottoms function as hydrological buffers that significantly affect runoff behavior. Distinguishing valley bottoms from hillslopes is an important first step in identifying and characterizing sediment deposits for hydrologic and geomorphic purposes. Valley bottoms occur at a range of scales from a few meters to hundreds of kilometers in extent. This paper describes an algorithm for using digital elevation models to identify valley bottoms based on their topographic signature as flat low-lying areas. The algorithm operates at a range of scales and combines the results at different scales into a single multiresolution index. This index classifies degrees of valley bottom flatness, which may be related to depth of deposit. The index can also be used to identify groundwater constrictions and to delineate hydrologic and geomorphic units.},
  langid = {english},
  keywords = {digital elevation model,landscape position,scale,slope,terrain analysis},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Gallant and Dowling - 2003 - A multiresolution index of valley bottom flatness .pdf}
}

@article{gatisMappingUplandPeat2019,
  title = {Mapping Upland Peat Depth Using Airborne Radiometric and Lidar Survey Data},
  author = {Gatis, N. and Luscombe, D.J. and Carless, D. and Parry, L.E. and Fyfe, R.M. and Harrod, T.R. and Brazier, R.E. and Anderson, K.},
  year = {2019},
  month = feb,
  journal = {Geoderma},
  volume = {335},
  pages = {78--87},
  issn = {00167061},
  doi = {10.1016/j.geoderma.2018.07.041},
  urldate = {2020-03-19},
  langid = {english},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Gatis et al_2019_Mapping upland peat depth using airborne radiometric and lidar survey data.pdf}
}

@techreport{gatisStAustellBodmin2023,
  title = {St {{Austell}}, {{Bodmin}}, {{Carnmenellis}} and {{Land}}'s {{End Peat Extent}} and {{Depth Mapping Report}} for the {{South West Peatland Partnership}} 2023},
  author = {Gatis, Naomi and Benaud, Pia and Goodger, Lou and Brazier, Richard and Anderson, Karen},
  year = {2023},
  abstract = {The South West Peatland Partnership have commissioned the University of Exeter to create a peat depth and extent map for the granite outcrops of Cornwall. Adapting methods previously developed for Dartmoor (Gatis et al., 2019) for the Cornubian batholith with site specific ground validation.},
  langid = {english},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Gatis et al. - St Austell, Bodmin, Carnmenellis and Land’s End Pe.pdf}
}

@article{giletAdaptiveMappingFramework2024,
  title = {An Adaptive Mapping Framework for the Management of Peat Soils: {{A}} New {{Irish}} Peat Soils Map},
  shorttitle = {An Adaptive Mapping Framework for the Management of Peat Soils},
  author = {Gilet, Louis and Morley, Terry R. and Flynn, Raymond and Connolly, John},
  year = {2024},
  month = jul,
  journal = {Geoderma},
  volume = {447},
  pages = {116933},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2024.116933},
  urldate = {2024-07-30},
  abstract = {Accurate mapping for effective management of peat soils is necessary to help reduce GHG emissions and improve environmental quality. However, mapping remains a major challenge as definitions of peat soils vary substantially between jurisdictions and organizations, while field data are sparse and difficult to produce, and remote sensing of limited use for converted peatlands. Using an Adaptive Mapping Framework, this paper compiles disparate data sources to update the Derived Irish Peat Map to better facilitate its application for environmental issues. This includes incorporation of areas considered to be underlain by shallow peat soils ({$\geq$} 10~cm and~{$\geq~$}8.6~\% Organic Matter content), and augmentation of the overall test dataset with an additional~{$\sim~$}20,000 points. The workflow for map generation employed 20 Decision Tree Output Maps (DTOMs), aggregated into 33 Map Combinations (MCs). These facilitated the addition of new areas and removal of areas where the presence of peat could not be confidently identified. The MC selected for the update had the highest accuracy metrics ({$\geq$} 74~\%), consisting of DTOMs with a user accuracy~{$\geq~$}66~\% and assessed over a minimum number of test points~{$\geq~$}50. The resulting map reveals peat to underlie 1.66~M~ha of Ireland ({$\sim$} 23.3~\% of the country), identified with values of 83~\% for overall accuracy and F1 score for peat areas. This extent is 13.2~\% larger than that delineated in previous versions and at least 23.2~\% larger than areas presented in other previous maps. The methodology also allows transparency from which data sources can be distinguished to define different key peat thickness ranges ({$\geq$} 10~cm, {$\geq$} 30--40~cm), better facilitating assessment of environmental impacts arising from land use change. This approach has potential relevance for peat mapping globally, notably in areas containing disparate datasets (e.g., land cover, soil map, etc.), or employing different production methods. The accuracy metrics generated also suggest that the approach can be used as a basis for implementing or updating national and international regulations concerning carbon-rich soils in comparable settings to those encountered in Ireland.},
  keywords = {data integration,Decision-tree,GIS,Ireland,management,peat,Peat mapping,Shallow peat soils,To read},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Gilet et al. - 2024 - An adaptive mapping framework for the management o.pdf}
}

@article{hapfelmeierEfficientPermutationTesting2023,
  title = {Efficient Permutation Testing of Variable Importance Measures by the Example of Random Forests},
  author = {Hapfelmeier, Alexander and Hornung, Roman and Haller, Bernhard},
  year = {2023},
  month = may,
  journal = {Computational Statistics \& Data Analysis},
  volume = {181},
  pages = {107689},
  issn = {0167-9473},
  doi = {10.1016/j.csda.2022.107689},
  urldate = {2024-08-27},
  abstract = {Hypothesis testing of variable importance measures (VIMPs) is still the subject of ongoing research. This particularly applies to random forests (RF), for which VIMPs are a popular feature. Among recent developments, heuristic approaches to parametric testing have been proposed whose distributional assumptions are based on empirical evidence. Other formal tests under regularity conditions were derived analytically. But these approaches can be computationally expensive or even practically infeasible. This problem also occurs with non-parametric permutation tests, which are, however, distribution-free and can generically be applied to any kind of prediction model and VIMP. Embracing this advantage, it is proposed to use sequential permutation tests and sequential p-value estimation to reduce the computational costs associated with conventional permutation tests. These costs can be particularly high in case of complex prediction models. Therefore, RF's popular and widely used permutation VIMP (pVIMP) serves as a practical and relevant application example. The results of simulation studies confirm the theoretical properties of the sequential tests, that is, the type-I error probability is controlled at a nominal level and a high power is maintained with considerably fewer permutations needed compared to conventional permutation testing. The numerical stability of the methods is investigated in two additional application studies. In summary, theoretically sound sequential permutation testing of VIMP is possible at greatly reduced computational costs. Recommendations for application are given. A respective implementation for RF's pVIMP is provided through the accompanying R package rfvimptest.},
  keywords = {Machine learning,p-value,Prediction model,Sequential permutation test,Variable selection},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Hapfelmeier et al. - 2023 - Efficient permutation testing of variable importan.pdf}
}

@article{henglGenericFrameworkSpatial2004,
  title = {A Generic Framework for Spatial Prediction of Soil Variables Based on Regression-Kriging},
  author = {Hengl, Tomislav and Heuvelink, Gerard B. M. and Stein, Alfred},
  year = {2004},
  month = may,
  journal = {Geoderma},
  volume = {120},
  number = {1},
  pages = {75--93},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2003.08.018},
  urldate = {2024-08-26},
  abstract = {A methodological framework for spatial prediction based on regression-kriging is described and compared with ordinary kriging and plain regression. The data are first transformed using logit transformation for target variables and factor analysis for continuous predictors (auxiliary maps). The target variables are then fitted using step-wise regression and residuals interpolated using kriging. A generic visualisation method is used to simultaneously display predictions and associated uncertainty. The framework was tested using 135 profile observations from the national survey in Croatia, divided into interpolation (100) and validation sets (35). Three target variables: organic matter, pH in topsoil and topsoil thickness were predicted from six relief parameters and nine soil mapping units. Prediction efficiency was evaluated using the mean error and root mean square error (RMSE) of prediction at validation points. The results show that the proposed framework improves efficiency of predictions. Moreover, it ensured normality of residuals and enforced prediction values to be within the physical range of a variable. For organic matter, it achieved lower relative RMSE than ordinary kriging (53.3\% versus 66.5\%). For topsoil thickness, it achieved a lower relative RMSE (66.5\% versus 83.3\%) and a lower bias than ordinary kriging (0.15 versus 0.69 cm). The prediction of pH in topsoil was difficult with all three methods. This framework can adopt both continuous and categorical soil variables in a semi-automated or automated manner. It opens a possibility to develop a bundle algorithm that can be implemented in a GIS to interpolate soil profile data from existing datasets.},
  keywords = {Environmental correlation,Factor analysis,Logit transformation,regression kriging,Spatial prediction,Visualisation},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Hengl et al. - 2004 - A generic framework for spatial prediction of soil.pdf}
}

@article{henglRandomForestGeneric2018,
  title = {Random Forest as a Generic Framework for Predictive Modeling of Spatial and Spatio-Temporal Variables},
  author = {Hengl, Tomislav and Nussbaum, Madlene and Wright, Marvin N. and Heuvelink, Gerard B. M. and Gr{\"a}ler, Benedikt},
  year = {2018},
  month = aug,
  journal = {PeerJ},
  volume = {6},
  pages = {e5518},
  publisher = {PeerJ Inc.},
  issn = {2167-8359},
  doi = {10.7717/peerj.5518},
  urldate = {2023-05-09},
  abstract = {Random forest and similar Machine Learning techniques are already used to generate spatial predictions, but spatial location of points (geography) is often ignored in the modeling process. Spatial auto-correlation, especially if still existent in the cross-validation residuals, indicates that the predictions are maybe biased, and this is suboptimal. This paper presents a random forest for spatial predictions framework (RFsp) where buffer distances from observation points are used as explanatory variables, thus incorporating geographical proximity effects into the prediction process. The RFsp framework is illustrated with examples that use textbook datasets and apply spatial and spatio-temporal prediction to numeric, binary, categorical, multivariate and spatiotemporal variables. Performance of the RFsp framework is compared with the state-of-the-art kriging techniques using fivefold cross-validation with refitting. The results show that RFsp can obtain equally accurate and unbiased predictions as different versions of kriging. Advantages of using RFsp over kriging are that it needs no rigid statistical assumptions about the distribution and stationarity of the target variable, it is more flexible towards incorporating, combining and extending covariates of different types, and it possibly yields more informative maps characterizing the prediction error. RFsp appears to be especially attractive for building multivariate spatial prediction models that can be used as ``knowledge engines'' in various geoscience fields. Some disadvantages of RFsp are the exponentially growing computational intensity with increase of calibration data and covariates and the high sensitivity of predictions to input data quality. The key to the success of the RFsp framework might be the training data quality---especially quality of spatial sampling (to minimize extrapolation problems and any type of bias in data), and quality of model validation (to ensure that accuracy is not effected by overfitting). For many data sets, especially those with lower number of points and covariates and close-to-linear relationships, model-based geostatistics can still lead to more accurate predictions than RFsp.},
  langid = {english},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Hengl et al. - 2018 - Random forest as a generic framework for predictiv.pdf}
}

@article{heuvelinkSpatialStatisticsSoil2022,
  title = {Spatial Statistics and Soil Mapping: {{A}} Blossoming Partnership under Pressure},
  shorttitle = {Spatial Statistics and Soil Mapping},
  author = {Heuvelink, Gerard B. M. and Webster, Richard},
  year = {2022},
  month = aug,
  journal = {Spatial Statistics},
  series = {Special {{Issue}}: {{The Impact}} of {{Spatial Statistics}}},
  volume = {50},
  pages = {100639},
  issn = {2211-6753},
  doi = {10.1016/j.spasta.2022.100639},
  urldate = {2023-06-21},
  abstract = {For the better part of the 20th century pedologists mapped soil by drawing boundaries between different classes of soil which they identified from survey on foot or by vehicle, supplemented by air-photo interpretation, and backed by an understanding of landscape and the processes by which soil is formed. Its limitations for representing gradual spatial variation and predicting conditions at unvisited sites became evident, and in the 1980s the introduction of geostatistics and specifically ordinary kriging revolutionized thinking and to a large extent practice. Ordinary kriging is based solely on sample data of the variable of interest---it takes no account of related covariates. The latter were incorporated from the 1990s onward as fixed effects and incorporated as regression predictors, giving rise to kriging with external drift and regression kriging. Simultaneous estimation of regression coefficients and variogram parameters is best done by residual maximum likelihood estimation. In recent years machine learning has become feasible for predicting soil conditions from huge sets of environmental data obtained from sensors aboard satellites and other sources to produce digital soil maps. The techniques are based on classification and regression, but they take no account of spatial correlations. Further, they are effectively `black boxes'; they lack transparency, and their output needs to be validated if they are to be trusted. They undoubtedly have merit; they are here to stay. They too, however, have their shortcomings when applied to spatial data, which spatial statisticians can help overcome. Spatial statisticians and pedometricians still have much to do to incorporate uncertainty into digital predictions, spatial averages and totals over regions, and to take into account errors in measurement and spatial positions of sample data. They must also communicate their understanding of these uncertainties to end users of soil maps, by whatever means they are made.},
  langid = {english},
  keywords = {Digital soil mapping,Geostatistics,Kriging,Machine learning,Pedometrics,Soil},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Heuvelink and Webster - 2022 - Spatial statistics and soil mapping A blossoming .pdf}
}

@article{hirzelWhichOptimalSampling2002,
  title = {Which Is the Optimal Sampling Strategy for Habitat Suitability Modelling},
  author = {Hirzel, Alexandre and Guisan, Antoine},
  year = {2002},
  month = nov,
  journal = {Ecological Modelling},
  volume = {157},
  number = {2},
  pages = {331--341},
  issn = {0304-3800},
  doi = {10.1016/S0304-3800(02)00203-X},
  urldate = {2023-05-09},
  abstract = {Designing an efficient sampling strategy is of crucial importance for habitat suitability modelling. This paper compares four such strategies, namely, `random', `regular', `proportional-stratified' and `equal-stratified'---to investigate (1) how they affect prediction accuracy and (2) how sensitive they are to sample size. In order to compare them, a virtual species approach (Ecol. Model. 145 (2001) 111) in a real landscape, based on reliable data, was chosen. The distribution of the virtual species was sampled 300 times using each of the four strategies in four sample sizes. The sampled data were then fed into a GLM to make two types of prediction: (1) habitat suitability and (2) presence/absence. Comparing the predictions to the known distribution of the virtual species allows model accuracy to be assessed. Habitat suitability predictions were assessed by Pearson's correlation coefficient and presence/absence predictions by Cohen's {$\kappa$} agreement coefficient. The results show the `regular' and `equal-stratified' sampling strategies to be the most accurate and most robust. We propose the following characteristics to improve sample design: (1) increase sample size, (2) prefer systematic to random sampling and (3) include environmental information in the design.},
  langid = {english},
  keywords = {Bootstrap statistics,GLM,Logistic model,Sampling design,SDM,Simulations,Virtual species},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Hirzel and Guisan - 2002 - Which is the optimal sampling strategy for habitat.pdf}
}

@incollection{hofierkaChapter17Geomorphometry2009,
  title = {Chapter 17 {{Geomorphometry}} in {{GRASS GIS}}},
  booktitle = {Developments in {{Soil Science}}},
  author = {Hofierka, J. and Mit{\'a}{\v s}ov{\'a}, H. and Neteler, M.},
  year = {2009},
  volume = {33},
  pages = {387--410},
  publisher = {Elsevier},
  doi = {10.1016/S0166-2481(08)00017-2},
  urldate = {2024-08-08},
  isbn = {978-0-12-374345-9},
  langid = {english},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Hofierka et al. - 2009 - Chapter 17 Geomorphometry in GRASS GIS.pdf}
}

@article{ivanovsModelingGeospatialDistribution2024,
  title = {Modeling {{Geospatial Distribution}} of {{Peat Layer Thickness Using Machine Learning}} and {{Aerial Laser Scanning Data}}},
  author = {Ivanovs, Janis and Haberl, Andreas and Melniks, Raitis},
  year = {2024},
  month = apr,
  journal = {Land},
  volume = {13},
  number = {4},
  pages = {466},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2073-445X},
  doi = {10.3390/land13040466},
  urldate = {2024-05-20},
  abstract = {Organic horizons including peat deposits are important terrestrial carbon pools, and various chemical, biological, and water exchange processes take place within them. Accurate information on the spatial distribution of organic soils and their properties is important for decision-making and land management. In this study, we present a machine learning approach for mapping the distribution of organic soils and determining the thickness of the peat layer using more than 24,000 peat layer thickness measurements obtained from field data, airborne laser scanning (ALS) data and various indices obtained from therein, as well as other cartographic materials. Our objectives encompassed two primary aims. Firstly, we endeavored to develop updated cartographic materials depicting the spatial distribution of peat layers. Secondly, we aimed to predict the depth of peat layers, thereby enhancing our understanding of soil organic carbon content. Continentality, a wet area map, latitude, a depth to water map with catchment area of 10 ha, and a digital elevation model were the most important covariates for the machine learning model. As a result, we obtained a map with three peat layer thickness classes, an overall classification accuracy of 0.88, and a kappa value of 0.74. This research contributes to a better understanding of organic soil dynamics and facilitates improved assessments of soil organic carbon stocks.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {digital soil mapping,machine learning,national forest inventories,peatland},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Ivanovs et al. - 2024 - Modeling Geospatial Distribution of Peat Layer Thi.pdf}
}

@misc{kavliEv39OrskogfjelletVik2021,
  title = {Ev. 39 {{{\O}rskogfjellet-Vik}}: {{Oppsummering}} Kartlegging Av Vegetasjonslag Og Myrdybder},
  author = {Kavli, Arne},
  year = {2021},
  month = jan,
  urldate = {2023-03-21},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\oppsummering-av-georadarundersokelser--myrdybder.p.pdf}
}

@inproceedings{keaneyGroundtruthingAirborneGeophysical2012,
  title = {Ground-Truthing Airborne Geophysical Data for Carbon Stock Monitoring},
  booktitle = {{{EAGE}}/{{GRSG Remote Sensing Workshop}}},
  author = {Keaney, A. and McKinley, J.M. and Ruffell, A. and Robinson, M. and Graham, C. and Hodgson, J. and Desissa, M.},
  year = {2012},
  abstract = {This research project uses previously generated airborne Tellus radiometric data (Tellus project, GSNI) and newly acquired data collected as part of the EU-funded Tellus Border project to improve peat depth models for Northern Ireland and the bordering counties of the Republic of Ireland. The theory being tested is that gamma radiation from rocks is attenuated by overlying peat. Improved peat depth models produced though the integration and calibration of the Tellus data against known peat depths are used to improve carbon stock estimations. A 6km test line of the airborne survey is undertaken every 4-6 weeks and flown at a series of different elevations to allow the data to be assessed temporally with different saturation levels. An associated field survey takes place every 4-6 weeks to obtain data on the ground to correspond as closely as possible to the timing of the airborne flight survey. Analysis techniques on the ground include magnetometry, resistivity, radiometrics, moisture content, GPR and peat probing. Results for the airborne flight survey and ground-based data collection indicate that similarities between the traces can be identified. Ground validation enables the effect of changes in factors such as soil moisture to be assessed for the airborne radiometric data.},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Keaney et al. - 2012 - Ground-truthing airborne geophysical data for carb.pdf}
}

@article{keaneySpatialStatisticsEstimate2013,
  title = {Spatial Statistics to Estimate Peat Thickness Using Airborne Radiometric Data},
  author = {Keaney, A. and McKinley, J. and Graham, C. and Robinson, M. and Ruffell, A.},
  year = {2013},
  month = aug,
  journal = {Spatial Statistics},
  series = {{{GeoENV2012}}: {{Geostatistics}} for {{Environmental Applications}}},
  volume = {5},
  pages = {3--24},
  issn = {2211-6753},
  doi = {10.1016/j.spasta.2013.05.003},
  urldate = {2022-02-08},
  abstract = {Soil carbon stores are a major component of the annual returns required by EU governments to the Intergovernmental Panel on Climate Change. Peat has a high proportion of soil carbon due to the relatively high carbon density of peat and organic-rich soils. For this reason it has become increasingly important to measure and model soil carbon stores and changes in peat stocks to facilitate the management of carbon changes over time. The approach investigated in this research evaluates the use of airborne geophysical (radiometric) data to estimate peat thickness using the attenuation of bedrock geology radioactivity by superficial peat cover. Remotely sensed radiometric data are validated with ground peat depth measurements combined with non-invasive geophysical surveys. Two field-based case studies exemplify and validate the results. Variography and kriging are used to predict peat thickness from point measurements of peat depth and airborne radiometric data and provide an estimate of uncertainty in the predictions. Cokriging, by assessing the degree of spatial correlation between recent remote sensed geophysical monitoring and previous peat depth models, is used to examine changes in peat stocks over time. The significance of the coregionalisation is that the spatial cross correlation between the remote and ground based data can be used to update the model of peat depth. The result is that by integrating remotely sensed data with ground geophysics, the need is reduced for extensive ground-based monitoring and invasive peat depth measurements. The overall goal is to provide robust estimates of peat thickness to improve estimates of carbon stocks. The implications from the research have a broader significance that promotes a reduction in the need for damaging onsite peat thickness measurement and an increase in the use of remote sensed data for carbon stock estimations.},
  langid = {english},
  keywords = {Cokriging,Geostatistics,Kriging,peat depth,radiometry,To read},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Keaney et al. - 2013 - Spatial statistics to estimate peat thickness usin.pdf}
}

@article{keskinRegressionKrigingWorkhorse2018,
  title = {Regression Kriging as a Workhorse in the Digital Soil Mapper's Toolbox},
  author = {Keskin, H. and Grunwald, S.},
  year = {2018},
  month = sep,
  journal = {Geoderma},
  volume = {326},
  pages = {22--41},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2018.04.004},
  urldate = {2023-06-12},
  abstract = {Appropriate scale, justifiably reliable, categorical and continuous spatial soil information is urgently needed to address environmental problems and ensure sustainability of ecosystem services at local, regional and global scales. Regression Kriging (RK) is one of the most popular, practical and robust hybrid spatial interpolation techniques in the digital soil mapper's toolbox that enables the modeling of soil distribution patterns at multiple scales in space and time. Several theoretical and applied aspects of RK have been discussed; however, there are no review studies, which quantify the essential factors affecting the performance of RK. Materials for this review were gathered from high-quality international soil science journals: Catena, Geoderma, and Soil Science Society of America from 2004 to 2014. A total of 142 different models from 40 different articles were examined. The following criteria were considered to evaluate their impacts on the prediction efficiency of RK: i) soil geographic region, ii) area of extent, iii) spatial resolution, iv) target soil properties and/or classes v) sampling design, vi) sampling size and density, vii) sample depth viii) soil-environmental factors as predictors, ix) methods of transformation, x) factor analysis, xi) regression type, xii) model used for variogram, xiii) nugget to total sill ratio, xiv) spatial autocorrelation range, xv) coefficient of variation of observed dataset, xvi) evaluation method (note that in previous publications the term `validation' has been used extensively in publications in pedometrics) and xvii) coefficient of determination. The historical development of RK, limitations and strengths of current RK studies, research gaps, and future trends in RK are discussed. A major finding is the inverse relationship between the accuracy of RK models and the variation of soil properties in the original datasets. Novel modified RK methods are proposed for further investigation to predict soil properties and classes.},
  langid = {english},
  keywords = {Accuracy,Digital soil mapping,Pedometrics,regression kriging,review,Soil spatial predictions models,To read},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Keskin and Grunwald - 2018 - Regression kriging as a workhorse in the digital s.pdf}
}

@misc{kogantiAssessingSuitabilityGroundpenetrating2024,
  title = {Assessing the Suitability of Ground-Penetrating Radar for Peat Imaging},
  author = {Koganti, Triven},
  year = {2024},
  month = feb,
  urldate = {2024-04-25},
  collaborator = {Adetsu, Diana Vigah and Henrion, Maud and Beucher, Am{\'e}lie Marie and Lambot, S{\'e}bastien and Greve, Mogens H.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Koganti - 2024 - Assessing the suitability of ground-penetrating ra.pdf}
}

@article{kogantiMappingPeatDepth2023,
  title = {Mapping Peat Depth Using a Portable Gamma-Ray Sensor and Terrain Attributes},
  author = {Koganti, Triven and Vigah Adetsu, Diana and Triantafilis, John and Greve, Mogens H. and Beucher, Am{\'e}lie Marie},
  year = {2023},
  month = nov,
  journal = {Geoderma},
  volume = {439},
  pages = {116672},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2023.116672},
  urldate = {2023-10-02},
  abstract = {Pristine peatlands being excellent storage for terrestrial Carbon (C) play a crucial role in regulating climate and water and provide several important ecosystem services. However, peatlands have been heavily altered (e.g., by draining the water table), increasing greenhouse gas (GHG) emissions. Restoring peatlands requires a comprehensive characterization, including knowledge of peat depth (PD; m). Traditionally, this requires the physical insertion of a push probe, which is time-consuming and labor-intensive. It has been shown that non-invasive proximal sensing techniques such as electromagnetic induction and ground penetrating radar can add value to PD data. In this research, we want to assess the potential of proximally sensed gamma-ray ({$\gamma$}-ray) spectrometry (i.e., potassium [K], thorium [Th], uranium [U], and the count rate [CR]) and terrain attributes data (i.e., elevation, slope, SAGAWI, and MRVBF) to map PD either alone or in combination across a small (10~ha) peatland area in {\O}Bakker, Denmark. Here, the PD varies from 0.1~m in the south to 7.3~m in the north. We use various prediction models including ordinary kriging (OK) of PD, linear regression (LR), multiple LR (MLR), LR kriging (LRK), MLR kriging (MLRK) and empirical Bayesian kriging regression (EBKR). We also determine the minimum calibration sample size required by decreasing sample size in decrements (i.e., n~=~100, 90, 80,{\dots}, 30). We compare these approaches using prediction agreement (Lin's concordance correlation coefficient; LCCC) and accuracy (root mean square error; RMSE). The results show that OK using maximum calibration size (n~=~108) had near perfect agreement (0.97) and accuracy (0.59~m), compared to LR (ln CR; 0.65 and 0.78~m, respectively) and MLR (ln K, Th, CR and elevation; 0.85 and 0.63~m). Improvements are achieved by adding residuals; LRK (0.95 and 0.71~m) and MLRK (0.96 and 0.51~m). The best results were obtained using EBKR (0.97 and 0.63~m) given all predictions were positive and no significant change in agreement and standard errors with the decrement of calibration sample size (e.g., n~=~30). The results have implications towards C stocks assessment and improved land use planning to control GHG emissions and slow down global warming.},
  keywords = {carbon,digital soil mapping,kriging,peat depth,proximal soil sensing,radiometry},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Koganti et al. - 2023 - Mapping peat depth using a portable gamma-ray sens.pdf}
}

@misc{kogantiSensorbasedMappingDanish2023a,
  title = {Sensor-Based Mapping of Danish Peatlands},
  author = {Koganti, Triven and Adetsu, Diana and Larsen, Martin and Mohr, Skovgaard and Beucher, Am{\'e}lie and Greve, Mogens},
  year = {2023},
  month = apr,
  abstract = {Pristine peatlands are precious for their Carbon (C) storage ability and the vast range of ecosystem services they provide. Globally, peatlands were heavily altered over the years especially by draining the water table for meeting energy and agricultural needs. Draining the peat results in its enhanced microbial decomposition, increased dissolved C leaching and increased susceptibility to peat fires, thus turning peatlands into C-source ecosystems. Currently, the carbon dioxide (CO2) released from degraded peatlands amounts to approximately 5\% of global anthropogenic emissions. Climate change concerns have sparked an interest to reduce these emissions and different initiatives are put forward for the protection, proper management, and restoration of the peatlands. Denmark has its own national goal of reducing CO2 emissions by 70\% by 2030; of which agriculture is expected to be a significant contributor. Comprehensive characterization of peat inventory providing status on the C stocks, water table depths and emissions is required for improved land use planning as almost 4.8 million tonnes of CO2 per annum is released from cultivated organic lands ({\textasciitilde} 170,000 ha in total). To achieve this, measurements of peat depth (PD) for volume characterization are invaluable. The conventional mapping approach of PD using peat probes is laborious, time-consuming, and provides only localized and discrete measurements. In addition, these manual probing measurements are also prone to errors as occasionally the probes are obstructed by stones, wood and human artefacts causing underestimation and other times they might easily penetrate the soil underlying the actual peat causing overestimation. In Denmark, we are comparing and contrasting the suitability of different electromagnetic sensors, precisely, working on electromagnetic induction (EMI), ground penetrating radar (GPR), and gamma-ray radiometric (GR) principles to accurately characterize the Danish peatlands. We are testing the sensors on both ground-based and air-borne configurations to improve the feasibility, increase accessibility and save costs. A novel drone-based transient EMI sensor is being designed in this direction. So far the results suggest that the EMI and GR techniques are promising to demarcate the peatland boundaries and estimate the PDs up to a certain extent; depending on the gradient in transition between the mineral and organic soils. Ground penetrating radar provided unequivocal results in high-resistive ombrotrophic peat while failing in low-resistive minerotrophic peat due to low signal penetration. In the drone-borne configuration, GR proved superior due to its ease of use and less to no success was achieved using a GPR. Moving forward, we plan on fusing the multisensor datasets using machine learning to improve the prediction accuracy of PDs, find a means for mapping water table depths and perform advanced modelling for comprehending the effects of different management scenarios on CO2 emissions.},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Koganti et al. - 2023 - SENSOR-BASED MAPPING OF DANISH PEATLANDS.pdf}
}

@article{lagacherieAnalysingImpactSoil2020,
  title = {Analysing the Impact of Soil Spatial Sampling on the Performances of {{Digital Soil Mapping}} Models and Their Evaluation: {{A}} Numerical Experiment on {{Quantile Random Forest}} Using Clay Contents Obtained from {{Vis-NIR-SWIR}} Hyperspectral Imagery},
  shorttitle = {Analysing the Impact of Soil Spatial Sampling on the Performances of {{Digital Soil Mapping}} Models and Their Evaluation},
  author = {Lagacherie, P. and Arrouays, D. and Bourennane, H. and Gomez, C. and {Nkuba-Kasanda}, L.},
  year = {2020},
  month = oct,
  journal = {Geoderma},
  volume = {375},
  pages = {114503},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2020.114503},
  urldate = {2023-06-21},
  abstract = {It has long been acknowledged that the soil spatial samplings used as inputs to DSM models are strong drivers -- and often limiting factors -- of the performances of such models. However, few studies have focused on evaluating this impact and identifying the related spatial sampling characteristics. In this study, a numerical experiment was conducted on this topic using the pseudo values of topsoil clay content obtained from an airborne Visible Near InfraRed-Short Wave InfraRed (Vis-NIR-SWIR) hyperspectral image in the Cap Bon region (Tunisia) as the source of the spatial sampling. Twelve thousand DSM models were built by running a Random Forest algorithm from soil spatial sampling of different sizes and average spacings (from 200~m to 2000~m) and different spatial distributions (from clustered to regularly distributed), aiming to mimic the various situations encountered when handling legacy data. These DSM models were evaluated with regard to both their prediction performances and their ability to estimate their overall and local uncertainties. Three evaluation methods were applied: a model-based one, a classical model-free one using 25\% of the sites removed from the initial soil data, and a reference one using a set of 100,000 independent sites selected by stratified random sampling over the entire region. The results showed that: 1) While, as expected, the performances of the DSM models increased when the spacing of the sample increased, this increase was diminished for the smallest spacing as soon as 50\% of the spatially structured variance was captured by the sampling, 2) Sampling that provided complete and even distributions in the geographical space and had as great spread of the target soil property as possible increased the DSM performances, while complete and even sampling distributions in the covariate space had less impacts, 3) Systematic underestimations of the overall uncertainty of DSM models were observed, that were all the more important that the sparse samplings poorly covered the real distribution of the target soil property and that the dense sampling were unevenly distributed in the geographical space, 4) The local uncertainties were underestimated for sparse sampling and over-estimated for dense sampling while being sensitive to the same sampling characteristics as overall uncertainty. Such finding have practical outcomes on sampling strategies and DSM model evaluation that are discussed.},
  langid = {english},
  keywords = {Quantile Random Forest,Sampling methods,Spatial distribution indicators,Uncertainty},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Lagacherie et al. - 2020 - Analysing the impact of soil spatial sampling on t.pdf}
}

@article{lamichhaneDigitalSoilMapping2019,
  title = {Digital Soil Mapping Algorithms and Covariates for Soil Organic Carbon Mapping and Their Implications: {{A}} Review},
  shorttitle = {Digital Soil Mapping Algorithms and Covariates for Soil Organic Carbon Mapping and Their Implications},
  author = {Lamichhane, Sushil and Kumar, Lalit and Wilson, Brian},
  year = {2019},
  month = oct,
  journal = {Geoderma},
  volume = {352},
  pages = {395--413},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2019.05.031},
  urldate = {2023-06-12},
  abstract = {This article reviews the current research and applications of various digital soil mapping (DSM) techniques used to map Soil Organic Carbon (SOC) concentration and stocks following a systematic mapping approach from 2013 until present (18 February 2019). It is intended that this review of relevant literature will assist prospective researchers by identifying knowledge clusters and gaps in relation to the digital mapping of SOC. Of 120 studies, most were clustered in some specific countries such as China, Australia and the USA. The highest number publications were in 2016 and 2017. Regarding the predictive models, there was a progression from Linear Models towards Machine Learning (ML) techniques, and hybrid models in Regression Kriging (RK) framework performed better than individual models. Multiple Linear Regression (MLR) was the most frequently used method for predicting SOC, although it was outperformed by other ML techniques in most studies. Random Forest (RF) was found to perform better than MLR and other ML techniques in most comparative studies. Other common and competitive techniques were Cubist, Neural Network (NN), Boosted Regression Tree (BRT), Support Vector Machine (SVM) and Geographically Weighted Regression (GWR). Due to the inconsistency in various comparative studies, it would be advisable to calibrate the competitive algorithms using specific experimental datasets. This review also reveals the environmental covariates that have been identified as the most important by RF technique in recent years in regard to digital mapping of SOC, which may assist in selecting optimum sets of environmental covariates for mapping SOC. Covariates representing organism/organic activities were among the most frequent among top five covariates, followed by the variables representing climate and topography. Climate was reported to be influential in determining the variation in SOC level at regional scales, followed by parent materials, topography and land use. However, for mapping at a resolution that represents smaller areas such as a farm- or plot-scale, land use and vegetation indices were stated to be more influential in predicting SOC. Furthermore, unlike a previous review work, all recent studies in this review incorporated validation and 41\% of them estimated spatially explicit prediction of uncertainty. Only 9.16\% studies performed external validation, whereas most studies used data-splitting and cross-validation techniques which may not be the best options for datasets obtained through non-probability sampling.},
  langid = {english},
  keywords = {algorithm,Covariates,cross validation,digital soil mapping,model performance,Soil organic carbon,Systematic mapping,Validation},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Lamichhane et al. - 2019 - Digital soil mapping algorithms and covariates for.pdf}
}

@article{lewisNestedcvPackageFast2023,
  title = {Nestedcv: An {{R}} Package for Fast Implementation of Nested Cross-Validation with Embedded Feature Selection Designed for Transcriptomics and High-Dimensional Data},
  shorttitle = {Nestedcv},
  author = {Lewis, Myles J and Spiliopoulou, Athina and Goldmann, Katriona and Pitzalis, Costantino and McKeigue, Paul and Barnes, Michael R},
  year = {2023},
  month = jan,
  journal = {Bioinformatics Advances},
  volume = {3},
  number = {1},
  pages = {vbad048},
  issn = {2635-0041},
  doi = {10.1093/bioadv/vbad048},
  urldate = {2024-08-16},
  abstract = {Although machine learning models are commonly used in medical research, many analyses implement a simple partition into training data and hold-out test data, with cross-validation (CV) for tuning of model hyperparameters. Nested CV with embedded feature selection is especially suited to biomedical data where the sample size is frequently limited, but the number of predictors may be significantly larger (P {$\gg$} n).The nestedcv R package implements fully nested k\,{\texttimes}\,l-fold CV for lasso and elastic-net regularized linear models via the glmnet package and supports a large array of other machine learning models via the caret framework. Inner CV is used to tune models and outer CV is used to determine model performance without bias. Fast filter functions for feature selection are provided and the package ensures that filters are nested within the outer CV loop to avoid information leakage from performance test sets. Measurement of performance by outer CV is also used to implement Bayesian linear and logistic regression models using the horseshoe prior over parameters to encourage a sparse model and determine unbiased model accuracy.The R package nestedcv is available from CRAN: https://CRAN.R-project.org/package=nestedcv.},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Lewis et al. - 2023 - nestedcv an R package for fast implementation of .pdf}
}

@article{liessInterfaceDomainKnowledge2020,
  title = {At the Interface between Domain Knowledge and Statistical Sampling Theory: {{Conditional}} Distribution Based Sampling for Environmental Survey ({{CODIBAS}})},
  shorttitle = {At the Interface between Domain Knowledge and Statistical Sampling Theory},
  author = {Lie{\ss}, M.},
  year = {2020},
  month = apr,
  journal = {CATENA},
  volume = {187},
  pages = {104423},
  issn = {0341-8162},
  doi = {10.1016/j.catena.2019.104423},
  urldate = {2023-06-28},
  abstract = {In environmental research, there is an extensive knowledge of the underlying processes that cause a distinct spatial landscape pattern of system properties. Statistical sampling theory deals with how a dataset must be constructed that allows for the transferability of the insights from the collected data to the system. Stratified and balanced sampling schemes applied for environmental survey, seek to reduce the necessary amount of data to capture the spatial heterogeneity of a landscape. The particular design's specification depends on the field of application. Against this background, the author strives to draw the attention to the conceptual shortcomings of conditioned Latin hypercube sampling (cLHS) in the context of soil survey and digital soil mapping. Furthermore, a new sampling design is presented which (1) combines the advantages of both, stratified and balanced designs, (2) shows consistency in the application of pedogenetic theory, and (3) which can be obtained by some simple modifications to the computer code of cLHS. Overall, this manuscript shall promote a vivid discussion in the Pedometrics community concerning the consideration of scientific domain knowledge in statistical sampling theory.},
  langid = {english},
  keywords = {Conditioned Latin hypercube,Environmental survey,Sampling,sampling design,Soil},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Ließ - 2020 - At the interface between domain knowledge and stat.pdf}
}

@article{liFactorsControllingPeat2024,
  title = {Factors Controlling Peat Soil Thickness and Carbon Storage in Temperate Peatlands Based on {{UAV}} High-Resolution Remote Sensing},
  author = {Li, Yanfei and Henrion, Maud and Moore, Angus and Lambot, S{\'e}bastien and Opfergelt, Sophie and Vanacker, Veerle and Jonard, Fran{\c c}ois and Van Oost, Kristof},
  year = {2024},
  month = sep,
  journal = {Geoderma},
  volume = {449},
  pages = {117009},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2024.117009},
  urldate = {2024-09-10},
  abstract = {Peatlands store a large amount of carbon. However, peatlands are complex ecosystems, and acquiring reliable estimates of how much carbon is stored underneath the Earth's surface is inherently challenging, even at small scales. Here, we aim to establish links between the above- and below-ground factors that control soil carbon status, identify the key environmental variables associated with carbon storage, as well as to explore the potential for using Unmanned Aerial Vehicle (UAV) remote sensing for spatial mapping of peatlands. We combine UAVs equipped with Red-Green-Blue (RGB), multispectral, thermal infrared, and light detection and ranging (LiDAR) sensors with ground-penetrating radar (GPR) technology and traditional field surveys to provide a comprehensive, 3-dimensional mapping of a peatland hillslope-floodplain landscape in the Belgian Hautes Fagnes. Our results indicate that both peat thickness and soil organic carbon (SOC) stock (top 1~m) are spatially heterogeneous and that the contributions from the surface topography to peat thickness and SOC stock varied from micro- to macro-scales. Peat thickness was more strongly controlled by macro-topography (R2~=~0.46) than SOC stock, which was more influenced by micro-topography (R2~=~0.21). Current vegetation had little predictive power for explaining their spatial variability. Additionally, the UAV data provided accurate estimates of both peat thickness and SOC stock, with RMSE and R2 values of 0.16~m and 0.85 for the peat thickness, and 59.25~t/ha and 0.85 for the SOC stock. However, similar performance can already be achieved by using only topographical data from the LiDAR sensor (for peat thickness) and a combination of peat thickness and topography (for SOC stock) as predictor variables. Our study bridges the gap between surface observations and the hidden carbon reservoir below. This not only allows us to improve our ability to assess the spatial distribution of SOC stocks, but also contributes to our understanding of the environmental factors associated with SOC storage in these highly heterogeneous landscapes, providing insights for environmental science and climate projections.},
  keywords = {_tablet,Carbon stock,Global warming,Peat thickness,Peatlands,Thermal and multispectral remote sensing,To read,UAV LiDAR},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Li et al. - 2024 - Factors controlling peat soil thickness and carbon.pdf}
}

@article{limburgDroneborneGammarayMapping2019,
  title = {Towards Drone-Borne Gammaray Mapping of Soils},
  author = {Limburg, Han and Van Der Veeke, Steven and Koomans, Ronald},
  year = {2019},
  month = aug,
  journal = {First Break},
  volume = {37},
  number = {8},
  pages = {55--61},
  issn = {0263-5046, 1365-2397},
  doi = {10.3997/1365-2397.n0048},
  urldate = {2024-04-25},
  langid = {english},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Limburg et al. - 2019 - Towards drone-borne gammaray mapping of soils.pdf}
}

@article{linnenbrinkKNNDMCVKfold2024,
  title = {{{kNNDM CV}}: {\emph{K}}-Fold Nearest-Neighbour Distance Matching Cross-Validation for Map Accuracy Estimation},
  shorttitle = {{{kNNDM CV}}},
  author = {Linnenbrink, Jan and Mil{\`a}, Carles and Ludwig, Marvin and Meyer, Hanna},
  year = {2024},
  month = aug,
  journal = {Geoscientific Model Development},
  volume = {17},
  number = {15},
  pages = {5897--5912},
  publisher = {Copernicus GmbH},
  issn = {1991-959X},
  doi = {10.5194/gmd-17-5897-2024},
  urldate = {2024-08-13},
  abstract = {Random and spatial cross-validation (CV) methods are commonly used to evaluate machine-learning-based spatial prediction models, and the performance values obtained are often interpreted as map accuracy estimates. However, the appropriateness of such approaches is currently the subject of controversy. For the common case where no probability sample for validation purposes is available, in Mil{\`a} et al. (2022) we proposed the nearest-neighbour distance matching (NNDM) leave-one-out (LOO) CV method. This method produces a distribution of geographical nearest-neighbour distances (NNDs) between test and training locations during CV that matches the distribution of NNDs between prediction and training locations. Hence, it creates predictive conditions during CV that are comparable to what is required when predicting a defined area. Although NNDM LOO CV produced largely reliable map accuracy estimates in our analysis, as a LOO-based method, it cannot be applied to the large datasets found in many studies.  Here, we propose a novel k-fold CV strategy for map accuracy estimation inspired by the concepts of NNDM LOO CV: the k-fold NNDM (kNNDM) CV. The kNNDM algorithm tries to find a k-fold configuration such that the empirical cumulative distribution function (ECDF) of NNDs between test and training locations during CV is matched to the ECDF of NNDs between prediction and training locations.  We tested kNNDM CV in a simulation study with different sampling distributions and compared it to other CV methods including NNDM LOO CV. We found that kNNDM CV performed similarly to NNDM LOO CV and produced reasonably reliable map accuracy estimates across sampling patterns. However, compared to NNDM LOO CV, kNNDM resulted in significantly reduced computation times. In an experiment using 4000 strongly clustered training points, kNNDM CV reduced the time spent on fold assignment and model training from 4.8 d to 1.2 min. Furthermore, we found a positive association between the quality of the match of the two ECDFs in kNNDM and the reliability of the map accuracy estimates.  kNNDM provided the advantages of our original NNDM LOO CV strategy while bypassing its sample size limitations.},
  langid = {english},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Linnenbrink et al. - 2024 - kNNDM CV k-fold nearest-neighbour distance.pdf}
}

@misc{linnenbrinkKNNDMKfoldNearest2023,
  title = {{{kNNDM}}: K-Fold {{Nearest Neighbour Distance Matching Cross-Validation}} for Map Accuracy Estimation},
  shorttitle = {{{kNNDM}}},
  author = {Linnenbrink, Jan and Mil{\`a}, Carles and Ludwig, Marvin and Meyer, Hanna},
  year = {2023},
  month = jul,
  publisher = {Copernicus GmbH},
  doi = {10.5194/egusphere-2023-1308},
  urldate = {2024-04-18},
  archiveprefix = {Copernicus GmbH},
  langid = {english},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Linnenbrink et al. - 2023 - kNNDM k-fold Nearest Neighbour Distance Matching .pdf}
}

@article{maComparisonConditionedLatin2020,
  title = {Comparison of Conditioned {{Latin}} Hypercube and Feature Space Coverage Sampling for Predicting Soil Classes Using Simulation from Soil Maps},
  author = {Ma, Tianwu and Brus, Dick J. and Zhu, A-Xing and Zhang, Lei and Scholten, Thomas},
  year = {2020},
  month = jul,
  journal = {Geoderma},
  volume = {370},
  pages = {114366},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2020.114366},
  urldate = {2023-06-21},
  abstract = {This study investigates sampling design for mapping soil classes based on multiple environmental features associated with the soil classes. Two types of sampling design for calibrating the prediction models are compared: conditioned Latin hypercube sampling (CLHS) and feature space coverage sampling (FSCS). Simple random sampling (SRS), which does not utilize the environmental features, is added as a reference design. The sample sizes used are 20, 30, 40, 50, 75, and 100 points, and at each sample size 100 sample sets were drawn using each of the three types of design. Each of these sample sets was then used to calibrate three prediction models: random forest (RF), individual predictive soil mapping (iPSM), and multinomial logistic regression (MLR). These sampling designs were compared based on the overall accuracy of predicted soil class maps obtained by these three prediction methods. The comparison was conducted in two study areas: Ammertal (Germany) and Raffelson (USA). For each of these two areas a detailed legacy soil class map is available. These soil class maps were used as references in a simulation study for the comparison. Results of both study areas show that on average FSCS outperforms CLHS and SRS for all three prediction methods. The difference in estimated medians of overall accuracy with CLHS and SRS was marginal. Moreover, the variation in overall accuracy among sample sets of the same size was considerably smaller for FSCS than that for CLHS. These results in the two study areas suggest that FSCS is a more effective sampling design.},
  langid = {english},
  keywords = {calibration,Random forest,Simulated annealing,soil mapping,Soil sampling},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Ma et al. - 2020 - Comparison of conditioned Latin hypercube and feat.pdf}
}

@misc{mahoneyAssessingPerformanceSpatial2023,
  title = {Assessing the Performance of Spatial Cross-Validation Approaches for Models of Spatially Structured Data},
  author = {Mahoney, Michael J. and Johnson, Lucas K. and Silge, Julia and Frick, Hannah and Kuhn, Max and Beier, Colin M.},
  year = {2023},
  month = mar,
  number = {arXiv:2303.07334},
  eprint = {2303.07334},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2303.07334},
  urldate = {2024-08-26},
  abstract = {Evaluating models fit to data with internal spatial structure requires specific cross-validation (CV) approaches, because randomly selecting assessment data may produce assessment sets that are not truly independent of data used to train the model. Many spatial CV methodologies have been proposed to address this by forcing models to extrapolate spatially when predicting the assessment set. However, to date there exists little guidance on which methods yield the most accurate estimates of model performance. We conducted simulations to compare model performance estimates produced by five common CV methods fit to spatially structured data. We found spatial CV approaches generally improved upon resubstitution and V-fold CV estimates, particularly when approaches which combined assessment sets of spatially conjunct observations with spatial exclusion buffers. To facilitate use of these techniques, we introduce the `spatialsample` package which provides tooling for performing spatial CV as part of the broader tidymodels modeling framework.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Computation,Statistics - Methodology},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Mahoney et al. - 2023 - Assessing the performance of spatial cross-validat.pdf}
}

@article{maloneMethodsImproveUtility2019,
  title = {Some Methods to Improve the Utility of Conditioned {{Latin}} Hypercube Sampling},
  author = {Malone, Brendan P. and Minansy, Budiman and Brungard, Colby},
  year = {2019},
  month = feb,
  journal = {PeerJ},
  volume = {7},
  pages = {e6451},
  publisher = {PeerJ Inc.},
  issn = {2167-8359},
  doi = {10.7717/peerj.6451},
  urldate = {2023-06-12},
  abstract = {The conditioned Latin hypercube sampling (cLHS) algorithm is popularly used for planning field sampling surveys in order to understand the spatial behavior of natural phenomena such as soils. This technical note collates, summarizes, and extends existing solutions to problems that field scientists face when using cLHS. These problems include optimizing the sample size, re-locating sites when an original site is deemed inaccessible, and how to account for existing sample data, so that under-sampled areas can be prioritized for sampling. These solutions, which we also share as individual R scripts, will facilitate much wider application of what has been a very useful sampling algorithm for scientific investigation of soil spatial variation.},
  langid = {english},
  keywords = {digital soil mapping,fieldwork,LHS,sampling design,To read},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Malone et al. - 2019 - Some methods to improve the utility of conditioned.pdf}
}

@article{maoEnvironmentalLandscapeDeterminants2019,
  title = {Environmental Landscape Determinants of Maximum Forest Canopy Height of Boreal Forests},
  author = {Mao, Lingfeng and Bater, Christopher W and Stadt, John J and White, Barry and Tompalski, Piotr and Coops, Nicholas C and Nielsen, Scott E},
  year = {2019},
  month = jan,
  journal = {Journal of Plant Ecology},
  volume = {12},
  number = {1},
  pages = {96--102},
  issn = {1752-993X},
  doi = {10.1093/jpe/rtx071},
  urldate = {2024-05-29},
  abstract = {Canopy height is a key driver of forest biodiversity and carbon cycling. Accurate estimates of canopy height are needed for assessing mechanisms relating to ecological patterns and processes of tree height limitations. At global scales forest canopy height patterns are largely controlled by climate, while local variation at fine scales is due to differences in disturbance history and local patterns in environmental conditions. The relative effect of local environmental drivers on canopy height is poorly understood partly due to gaps in data on canopy height and methods for examining limiting factors. Here, we used airborne laser scanning (ALS) data on vegetation structure of boreal forests to examine the effects of environmental factors on potential maximum forest canopy height.Relationships between maximum canopy height from ALS measures and environmental variables were examined to assess factors limiting tree height. Specifically, we used quantile regression at the 0.90 quantile to relate maximum canopy height with environmental characteristics of climate (i.e. mean annual temperature [MAT] and mean annual precipitation), terrain (i.e. slope) and depth-to-water (DTW) across a 33000 km2 multiple use boreal forest landscape in northeast Alberta, Canada.Maximum canopy height was positively associated with MAT, terrain slope and terrain-derived DTW, collectively explaining 33.2\% of the variation in heights. The strongest explanatory variable was DTW explaining 26\% of canopy height variation with peatland forests having naturally shorter maximum canopy heights, but also more sites currently at their maximum potential height. In contrast, the most productive forests (i.e. mesic to xeric upland forests) had the fewest sites at their potential maximum height, illustrating the effects of long-term forest management, wildfires and general anthropogenic footprints on reducing the extent and abundance of older, taller forest habitat in Alberta's boreal forest.},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Mao et al. - 2019 - Environmental landscape determinants of maximum fo.pdf}
}

@inproceedings{marchantPredictionPeatDepths2021,
  title = {Prediction of Peat Depths Using Airborne Radiometric Data: Optimization of Ground Surveys.},
  shorttitle = {Prediction of Peat Depths Using Airborne Radiometric Data},
  booktitle = {{{EGU21}}},
  author = {Marchant, Ben},
  year = {2021},
  month = mar,
  publisher = {Copernicus Meetings},
  doi = {10.5194/egusphere-egu21-5827},
  urldate = {2024-09-12},
  abstract = {The use of remote sensing data can lead to great efficiencies when mapping soil variables across broad regions. However, remote sensors rarely make direct measurements of the soil property of interest. Instead, an empirical model is required to relate the remote sensing data to ground measurements of the property of interest. We discuss how a survey of ground measurements required to calibrate such a model can be optimized. We make reference to the mapping of peat depth within the Dartmoor National Park (UK) using radiometric potassium data from an airborne survey of the region (http://www.tellusgb.ac.uk/). We expand the standard linear mixed model to accommodate nonlinear relationships between radiometric potassium and peat depths. The attenuation of the radiometric signal is seen to increase with peat depth, but the depth is particularly uncertain when the radiometric signal is small. When a spatial simulated annealing algorithm is used to optimize the locations for a survey of peat depth measurements to minimize the errors in the maps of peat depth upon use of the radiometric data, the complete range of the radiometric data are sampled but ground measurements are particularly focussed where the radiometric signal is small. We see that an optimized survey of 30 ground measurements combined with the radiometric data lead to more accurate maps than can be achieved from interpolation of more than 200 peat depth measurements.},
  langid = {english}
}

@article{marchantUsingRemoteSensors2021,
  title = {Using Remote Sensors to Predict Soil Properties: {{Radiometry}} and Peat Depth in {{Dartmoor}}, {{UK}}},
  shorttitle = {Using Remote Sensors to Predict Soil Properties},
  author = {Marchant, B. P.},
  year = {2021},
  month = dec,
  journal = {Geoderma},
  volume = {403},
  pages = {115232},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2021.115232},
  urldate = {2021-11-17},
  abstract = {Remote sensors provide high resolution data over large spatial extents that can potentially be used to map soil properties such as the concentration of organic carbon or its moisture content. The sensors rarely measure the property of interest directly but instead measure a related property. There is a need to make ground measurements of the property of interest to calibrate a model or relationship between the soil property and the sensor data. We develop a framework for optimizing the locations and number of ground measurements of a soil property for surveys incorporating sensor data. The data are used to estimate a linear mixed model of the property where the fixed effects are a flexible spline-based function of the sensor measurements. The framework is used to map peat depth across a portion of Dartmoor National Park using radiometric potassium data measurements from an airborne survey. The most accurate maps result from using a geostatistical predictor to combine the relationship with the sensor data and the spatial correlation amongst the peat depth measurements. The optimal sampling designs suggest that ground measurements should be focussed where peat depths are largest and most uncertain. When measurements are made at 25 optimally selected sites, predictions that do not utilise the sensor data have 20\% larger root mean square errors than those that do. For 200 ground measurements this benefit is 14\%. The maps produced using the sensor data and 25 ground measurements have smaller root mean square errors than those based only upon 200 ground measurements.},
  langid = {english},
  keywords = {peat depth,peatland,radiometry,sampling design,splines,To read},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Marchant_2021_Using remote sensors to predict soil properties.pdf}
}

@article{mattiviTWIComputationComparison2019,
  title = {{{TWI}} Computation: A Comparison of Different Open Source {{GISs}}},
  shorttitle = {{{TWI}} Computation},
  author = {Mattivi, Pietro and Franci, Francesca and Lambertini, Alessandro and Bitelli, Gabriele},
  year = {2019},
  month = jul,
  journal = {Open Geospatial Data, Software and Standards},
  volume = {4},
  number = {1},
  pages = {6},
  issn = {2363-7501},
  doi = {10.1186/s40965-019-0066-y},
  urldate = {2024-04-11},
  abstract = {The opportunities of retrieving geospatial datasets as open data and the reliability of Free and Open Source Software (FOSS) GIS increased the possibilities of performing a large number of geospatial analyses. In particular, the worldwide availability of Digital Elevation Model (DEM) permits to compute several topographic indexes able to characterize the land morphology.},
  keywords = {DEM,FOSS,GIS,Morphometric parameters,Topographic wetness index},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Mattivi et al. - 2019 - TWI computation a comparison of different open so.pdf}
}

@misc{meyerCASTPackageTraining2024,
  title = {The {{CAST}} Package for Training and Assessment of Spatial Prediction Models in {{R}}},
  author = {Meyer, Hanna and Ludwig, Marvin and Mil{\`a}, Carles and Linnenbrink, Jan and Schumacher, Fabian},
  year = {2024},
  month = apr,
  number = {arXiv:2404.06978},
  eprint = {2404.06978},
  primaryclass = {cs, q-bio, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2404.06978},
  urldate = {2024-08-16},
  abstract = {One key task in environmental science is to map environmental variables continuously in space or even in space and time. Machine learning algorithms are frequently used to learn from local field observations to make spatial predictions by estimating the value of the variable of interest in places where it has not been measured. However, the application of machine learning strategies for spatial mapping involves additional challenges compared to "non-spatial" prediction tasks that often originate from spatial autocorrelation and from training data that are not independent and identically distributed. In the past few years, we developed a number of methods to support the application of machine learning for spatial data which involves the development of suitable cross-validation strategies for performance assessment and model selection, spatial feature selection, and methods to assess the area of applicability of the trained models. The intention of the CAST package is to support the application of machine learning strategies for predictive mapping by implementing such methods and making them available for easy integration into modelling workflows. Here we introduce the CAST package and its core functionalities. At the case study of mapping plant species richness, we will go through the different steps of the modelling workflow and show how CAST can be used to support more reliable spatial predictions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Quantitative Methods,Statistics - Machine Learning},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Meyer et al. - 2024 - The CAST package for training and assessment of sp.pdf}
}

@article{meyerImportanceSpatialPredictor2019,
  title = {Importance of Spatial Predictor Variable Selection in Machine Learning Applications -- {{Moving}} from Data Reproduction to Spatial Prediction},
  author = {Meyer, Hanna and Reudenbach, Christoph and W{\"o}llauer, Stephan and Nauss, Thomas},
  year = {2019},
  month = nov,
  journal = {Ecological Modelling},
  volume = {411},
  pages = {108815},
  issn = {0304-3800},
  doi = {10.1016/j.ecolmodel.2019.108815},
  urldate = {2024-08-13},
  abstract = {Machine learning algorithms find frequent application in spatial prediction of biotic and abiotic environmental variables. However, the characteristics of spatial data, especially spatial autocorrelation, are widely ignored. We hypothesize that this is problematic and results in models that can reproduce training data but are unable to make spatial predictions beyond the locations of the training samples. We assume that not only spatial validation strategies but also spatial variable selection is essential for reliable spatial predictions. We introduce two case studies that use remote sensing to predict land cover and the leaf area index for the ``Marburg Open Forest'', an open research and education site of Marburg University, Germany. We use the machine learning algorithm Random Forests to train models using non-spatial and spatial cross-validation strategies to understand how spatial variable selection affects the predictions. Our findings confirm that spatial cross-validation is essential in preventing overoptimistic model performance. We further show that highly autocorrelated predictors (such as geolocation variables, e.g. latitude, longitude) can lead to considerable overfitting and result in models that can reproduce the training data but fail in making spatial predictions. The problem becomes apparent in the visual assessment of the spatial predictions that show clear artefacts that can be traced back to a misinterpretation of the spatially autocorrelated predictors by the algorithm. Spatial variable selection could automatically detect and remove such variables that lead to overfitting, resulting in reliable spatial prediction patterns and improved statistical spatial model performance. We conclude that in addition to spatial validation, a spatial variable selection must be considered in spatial prediction models of ecological data to produce reliable results.},
  keywords = {Cross-validation,Environmental monitoring,Machine learning,Overfitting,Random Forests,Remote sensing,To read},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Meyer et al. - 2019 - Importance of spatial predictor variable selection.pdf}
}

@article{meyerImprovingPerformanceSpatiotemporal2018,
  title = {Improving Performance of Spatio-Temporal Machine Learning Models Using Forward Feature Selection and Target-Oriented Validation},
  author = {Meyer, Hanna and Reudenbach, Christoph and Hengl, Tomislav and Katurji, Marwan and Nauss, Thomas},
  year = {2018},
  month = mar,
  journal = {Environmental Modelling \& Software},
  volume = {101},
  pages = {1--9},
  issn = {1364-8152},
  doi = {10.1016/j.envsoft.2017.12.001},
  urldate = {2024-08-13},
  abstract = {Importance of target-oriented validation strategies for spatio-temporal prediction models is illustrated using two case studies: (1) modelling of air temperature (Tair) in Antarctica, and (2) modelling of volumetric water content (VW) for the R.J. Cook Agronomy Farm, USA. Performance of a random k-fold cross-validation (CV) was compared to three target-oriented strategies: Leave-Location-Out (LLO), Leave-Time-Out (LTO), and Leave-Location-and-Time-Out (LLTO) CV. Results indicate that considerable differences between random k-fold (R2~=~0.9 for Tair and 0.92 for VW) and target-oriented CV (LLO R2~=~0.24 for Tair and 0.49 for VW) exist, highlighting the need for target-oriented validation to avoid an overoptimistic view on models. Differences between random k-fold and target-oriented CV indicate spatial over-fitting caused by misleading variables. To decrease over-fitting, a forward feature selection in conjunction with target-oriented CV is proposed. It decreased over-fitting and simultaneously improved target-oriented performances (LLO CV R2~=~0.47 for Tair and 0.55 for VW).},
  keywords = {Cross-validation,Feature selection,Over-fitting,Random forest,Spatio-temporal,Target-oriented validation}
}

@article{meyerMachineLearningbasedGlobal2022,
  title = {Machine Learning-Based Global Maps of Ecological Variables and the Challenge of Assessing Them},
  author = {Meyer, Hanna and Pebesma, Edzer},
  year = {2022},
  month = apr,
  journal = {Nature Communications},
  volume = {13},
  number = {1},
  pages = {2208},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-29838-9},
  urldate = {2024-08-13},
  abstract = {The recent wave of published global maps of ecological variables has caused as much excitement as it has received criticism. Here we look into the data and methods mostly used for creating these maps, and discuss whether the quality of predicted values can be assessed, globally and locally.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {cross validation,mapping,model evaluation,spatial autocorrelation,To read},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Meyer and Pebesma - 2022 - Machine learning-based global maps of ecological v.pdf}
}

@article{meyerPredictingUnknownSpace2021,
  title = {Predicting into Unknown Space? {{Estimating}} the Area of Applicability of Spatial Prediction Models},
  shorttitle = {Predicting into Unknown Space?},
  author = {Meyer, Hanna and Pebesma, Edzer},
  year = {2021},
  journal = {Methods in Ecology and Evolution},
  volume = {12},
  number = {9},
  pages = {1620--1633},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.13650},
  urldate = {2024-08-13},
  abstract = {Machine learning algorithms have become very popular for spatial mapping of the environment due to their ability to fit nonlinear and complex relationships. However, this ability comes with the disadvantage that they can only be applied to new data if these are similar to the training data. Since spatial mapping requires predictions to new geographic space which in many cases goes along with new predictor properties, a method to assess the area to which a prediction model can be reliably applied is required. Here, we suggest a methodology that delineates the `area of applicability' (AOA) that we define as the area where we enabled the model to learn about relationships based on the training data, and where the estimated cross-validation performance holds. We first propose a `dissimilarity index' (DI) that is based on the minimum distance to the training data in the multidimensional predictor space, with predictors being weighted by their respective importance in the model. The AOA is then derived by applying a threshold which is the (outlier-removed) maximum DI of the training data derived via cross-validation. We further use the relationship between the DI and the cross-validation performance to map the estimated performance of predictions. We illustrate the approach in a simulated case study chosen to mimic ecological realities and test the credibility by using a large set of simulated data. The simulation studies showed that the prediction error within the AOA is comparable to the cross-validation error of the trained model, while the cross-validation error does not apply outside the AOA. This applies to models being trained with randomly distributed training data, as well as when training data are clustered in space and where spatial cross-validation is applied. Using the relationship between DI and cross-validation performance showed potential to limit predictions to the area where a user-defined performance applies. We suggest to add the AOA computation to the modeller's standard toolkit and to present predictions for the AOA only. We further suggest to report a map of DI-dependent performance estimates alongside prediction maps and complementary to (cross-)validation performance measures and the common uncertainty estimates.},
  copyright = {{\copyright} 2021 The Authors. Methods in Ecology and Evolution published by John Wiley \& Sons Ltd on behalf of British Ecological Society},
  langid = {english},
  keywords = {machine learning,model transferability,predictive modelling,Random Forest,remote sensing,spatial mapping,To read,uncertainty},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Meyer and Pebesma - 2021 - Predicting into unknown space Estimating the area.pdf}
}

@article{milaNearestNeighbourDistance2022,
  title = {Nearest Neighbour Distance Matching {{Leave-One-Out Cross-Validation}} for Map Validation},
  author = {Mil{\`a}, Carles and Mateu, Jorge and Pebesma, Edzer and Meyer, Hanna},
  year = {2022},
  journal = {Methods in Ecology and Evolution},
  volume = {13},
  number = {6},
  pages = {1304--1316},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.13851},
  urldate = {2024-08-13},
  abstract = {Several spatial and non-spatial Cross-Validation (CV) methods have been used to perform map validation when additional sampling for validation purposes is not possible, yet it is unclear in which situations one CV method might be preferred over the other. Three factors have been identified as determinants of the performance of CV methods for map validation: the prediction area (geographical interpolation vs. extrapolation), the sampling pattern and the landscape spatial autocorrelation. In this study, we propose a new CV strategy that takes the geographical prediction space into account, and test how the new method compares with other established CV methods under different configurations of these three factors. We propose a variation of Leave-One-Out (LOO) CV for map validation, called Nearest Neighbour Distance Matching (NNDM) LOO CV, in which the nearest neighbour distance distribution function between the test and training data during the CV process is matched to the nearest neighbour distance distribution function between the target prediction and training points. Using random forest as a machine learning algorithm, we then examine the suitability of NNDM LOO CV as well as the established LOO (non-spatial) and buffered-LOO (bLOO, spatial) CV methods in two simulations with varying prediction areas, landscape autocorrelation and sampling distributions. LOO CV provided good map accuracy estimates in landscapes with short autocorrelation ranges, or when estimating geographical interpolation map accuracy with randomly distributed samples. bLOO CV yielded realistic error estimates when estimating map accuracy in new prediction areas, but generally overestimated geographical interpolation errors. NNDM LOO CV returned reliable estimates in all scenarios we considered. While LOO and bLOO CV provided reliable map accuracy estimates only in certain situations, our newly proposed NNDM LOO CV method returned robust estimates and generalised to LOO and bLOO CV whenever these methods were the most appropriate approach. Our work recognises the necessity of considering the geographical prediction space when designing CV-based methods for map validation.},
  copyright = {{\copyright} 2022 The Authors. Methods in Ecology and Evolution published by John Wiley \& Sons Ltd on behalf of British Ecological Society.},
  langid = {english},
  keywords = {Cross-Validation,map accuracy estimation,map validation,spatial point patterns,spatial prediction,To read},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Milà et al. - 2022 - Nearest neighbour distance matching Leave-One-Out .pdf}
}

@article{minasnyConditionedLatinHypercube2006,
  title = {A Conditioned {{Latin}} Hypercube Method for Sampling in the Presence of Ancillary Information},
  author = {Minasny, Budiman and McBratney, Alex B.},
  year = {2006},
  month = nov,
  journal = {Computers \& Geosciences},
  volume = {32},
  number = {9},
  pages = {1378--1388},
  issn = {0098-3004},
  doi = {10.1016/j.cageo.2005.12.009},
  urldate = {2023-05-09},
  abstract = {This paper presents the conditioned Latin hypercube as a sampling strategy of an area with prior information represented as exhaustive ancillary data. Latin hypercube sampling (LHS) is a stratified random procedure that provides an efficient way of sampling variables from their multivariate distributions. It provides a full coverage of the range of each variable by maximally stratifying the marginal distribution. For conditioned Latin hypercube sampling (cLHS) the problem is: given N sites with ancillary variables (X), select x a sub-sample of size n (n{$\NestedLessLess$}N) in order that x forms a Latin hypercube, or the multivariate distribution of X is maximally stratified. This paper presents the cLHS method with a search algorithm based on heuristic rules combined with an annealing schedule. The method is illustrated with a simple 3-D example and an application in digital soil mapping of part of the Hunter Valley of New South Wales, Australia. Comparison is made with other methods: random sampling, and equal spatial strata. The results show that the cLHS is the most effective way to replicate the distribution of the variables.},
  langid = {english},
  keywords = {Optimisation,Sampling design,Simulated annealing,Soil survey,Spatial design},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Minasny and McBratney - 2006 - A conditioned Latin hypercube method for sampling .pdf}
}

@article{minasnyDigitalMappingPeatlands2019,
  title = {Digital Mapping of Peatlands -- {{A}} Critical Review},
  author = {Minasny, Budiman and Berglund, {\"O}rjan and Connolly, John and Hedley, Carolyn and {de Vries}, Folkert and Gimona, Alessandro and Kempen, Bas and Kidd, Darren and Lilja, Harry and Malone, Brendan and McBratney, Alex and Roudier, Pierre and O'Rourke, Sharon and {Rudiyanto} and Padarian, Jos{\'e} and Poggio, Laura and {ten Caten}, Alexandre and Thompson, Daniel and Tuve, Clint and Widyatmanti, Wirastuti},
  year = {2019},
  month = sep,
  journal = {Earth-Science Reviews},
  volume = {196},
  pages = {102870},
  issn = {0012-8252},
  doi = {10.1016/j.earscirev.2019.05.014},
  urldate = {2020-03-02},
  abstract = {Peatlands offer a series of ecosystem services including carbon storage, biomass production, and climate regulation. Climate change and rapid land use change are degrading peatlands, liberating their stored carbon (C) into the atmosphere. To conserve peatlands and help in realising the Paris Agreement, we need to understand their extent, status, and C stocks. However, current peatland knowledge is vague---estimates of global peatland extent ranges from 1 to 4.6\,million km2, and C stock estimates vary between 113 and 612 Pg (or billion tonne C). This uncertainty mostly stems from the coarse spatial scale of global soil maps. In addition, most global peatland estimates are based on rough country inventories and reports that use outdated data. This review shows that digital mapping using field observations combined with remotely-sensed images and statistical models is an avenue to more accurately map peatlands and decrease this knowledge gap. We describe peat mapping experiences from 12 countries or regions and review 90 recent studies on peatland mapping. We found that interest in mapping peat information derived from satellite imageries and other digital mapping technologies is growing. Many studies have delineated peat extent using land cover from remote sensing, ecology, and environmental field studies, but rarely perform validation, and calculating the uncertainty of prediction is rare. This paper then reviews various proximal and remote sensing techniques that can be used to map peatlands. These include geophysical measurements (electromagnetic induction, resistivity measurement, and gamma radiometrics), radar sensing (SRTM, SAR), and optical images (Visible and Infrared). Peatland is better mapped when using more than one covariate, such as optical and radar products using nonlinear machine learning algorithms. The proliferation of satellite data available in an open-access format, availability of machine learning algorithms in an open-source computing environment, and high-performance computing facilities could enhance the way peatlands are mapped. Digital soil mapping allows us to map peat in a cost-effective, objective, and accurate manner. Securing peatlands for the future, and abating their contribution to atmospheric C levels, means digitally mapping them now.},
  langid = {english},
  keywords = {remote sensing},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Minasny et al_2019_Digital mapping of peatlands – A critical review.pdf}
}

@article{minasnyMappingMonitoringPeatland2023,
  title = {Mapping and Monitoring Peatland Conditions from Global to Field Scale},
  author = {Minasny, Budiman and Adetsu, Diana Vigah and Aitkenhead, Matt and Artz, Rebekka R. E. and Baggaley, Nikki and Barthelmes, Alexandra and Beucher, Am{\'e}lie and Caron, Jean and Conchedda, Giulia and Connolly, John and Deragon, Rapha{\"e}l and Evans, Chris and Fadnes, Kjetil and Fiantis, Dian and Gagkas, Zisis and Gilet, Louis and Gimona, Alessandro and Glatzel, Stephan and Greve, Mogens H. and Habib, Wahaj and Hergoualc'h, Kristell and Hermansen, Cecilie and Kidd, Darren B. and Koganti, Triven and Kopansky, Dianna and Large, David J. and Larmola, Tuula and Lilly, Allan and Liu, Haojie and Marcus, Matthew and Middleton, Maarit and Morrison, Keith and Petersen, Rasmus Jes and Quaife, Tristan and Rochefort, Line and {Rudiyanto} and Toca, Linda and Tubiello, Francesco N. and Weber, Peter Lystb{\ae}k and Weldon, Simon and Widyatmanti, Wirastuti and Williamson, Jenny and Zak, Dominik},
  year = {2023},
  month = oct,
  journal = {Biogeochemistry},
  issn = {1573-515X},
  doi = {10.1007/s10533-023-01084-1},
  urldate = {2023-10-27},
  abstract = {Peatlands cover only 3--4\% of the Earth's surface, but they store nearly 30\% of global soil carbon stock. This significant carbon store is under threat as peatlands continue to be degraded at alarming rates around the world. It has prompted countries worldwide to establish regulations to conserve and reduce emissions from this carbon rich ecosystem. For example, the EU has implemented new rules that mandate sustainable management of peatlands, critical to reaching the goal of carbon neutrality by 2050. However, a lack of information on the extent and condition of peatlands has hindered the development of national policies and restoration efforts. This paper reviews the current state of knowledge on mapping and monitoring peatlands from field sites to the globe and identifies areas where further research is needed. It presents an overview of the different methodologies used to map peatlands in nine countries, which vary in definition of peat soil and peatland, mapping coverage, and mapping detail. Whereas mapping peatlands across the world with only one approach is hardly possible, the paper highlights the need for more consistent approaches within regions having comparable peatland types and climates to inform their protection and urgent restoration. The review further summarises various approaches used for monitoring peatland conditions and functions. These include monitoring at the plot scale for degree of humification and stoichiometric ratio, and proximal sensing such as gamma radiometrics and electromagnetic induction at the field to landscape scale for mapping~peat thickness and identifying~hotspots for greenhouse gas (GHG) emissions. Remote sensing techniques with passive and active sensors at regional to national scale can~help in monitoring subsidence rate, water table, peat moisture, landslides, and GHG emissions. Although the use of water table depth as a proxy for interannual GHG emissions from peatlands has been well established, there is no single remote sensing method or data product yet that has been verified beyond local or regional scales. Broader land-use change and fire monitoring at a global scale may further assist national GHG inventory reporting. Monitoring of peatland conditions to evaluate the success of individual restoration schemes still requires field work to assess local proxies combined with remote sensing and modeling. Long-term monitoring is necessary to draw valid conclusions on revegetation outcomes and associated GHG emissions in rewetted peatlands, as their dynamics are not fully understood at the~site level. Monitoring vegetation development and hydrology of restored peatlands is needed as a proxy to assess the return of water and changes in nutrient cycling and biodiversity.},
  langid = {english},
  keywords = {Climate change,Greenhouse gas emission,mapping,Nature-based solutions,Organic carbon,Organic soils,peatland,To read},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Minasny et al. - 2023 - Mapping and monitoring peatland conditions from gl.pdf}
}

@article{murphyMappingWetlandsComparison2007,
  title = {Mapping Wetlands: {{A}} Comparison of Two Different Approaches for {{New Brunswick}}, {{Canada}}},
  shorttitle = {Mapping Wetlands},
  author = {Murphy, Paul N. C. and Ogilvie, Jae and Connor, Kevin and Arp, Paul A.},
  year = {2007},
  month = dec,
  journal = {Wetlands},
  volume = {27},
  number = {4},
  pages = {846--854},
  issn = {1943-6246},
  doi = {10.1672/0277-5212(2007)27[846:MWACOT]2.0.CO;2},
  urldate = {2024-08-06},
  abstract = {Wetlands have an important role in ecosystem function and biodiversity. Effective management of wetlands requires accurate and comprehensive spatial information on location, size, classification, and connectivity in the landscape. Using a GIS, two provincial wetland maps were compared with regard to their areal correspondence across different ecoregions of New Brunswick. The first consisted of discrete wetland units (vector data) derived from aerial photo interpretation. The second consisted of wet areas modeled by a newly developed depth-to-water index with continuous coverage across the landscape (raster data). This index was derived from a digital elevation model and hydrographic data. The relative advantages and disadvantages of the two approaches were assessed. The two maps were generally consistent with most discrete wetland areas (51\%--67\%) embedded in the 0-- 10 cm depth-to-water class, verifying the continuous modeling approach. The continuous model identified a larger wetland area. Much of this additional area consisted of riparian zones and numerous small wetlands ({$<$} 1 ha) that were not captured by aerial photo interpretation. Unlike the discrete map, the continuous model showed the hydrological connectivity of wetlands across the landscape. Both approaches revealed that topography was a major control on wetland distribution between ecoregions, with more wetland in ecoregions with flatter topography.},
  langid = {english},
  keywords = {depth-to-water,GIS,riparian zones,soil mapping,soil wetness index,topographic modeling,topography,wetland management},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Murphy et al. - 2007 - Mapping wetlands A comparison of two different ap.pdf}
}

@article{murphyModellingMappingTopographic2011,
  title = {Modelling and Mapping Topographic Variations in Forest Soils at High Resolution: {{A}} Case Study},
  shorttitle = {Modelling and Mapping Topographic Variations in Forest Soils at High Resolution},
  author = {Murphy, Paul N. C. and Ogilvie, Jae and Meng, Fan-Rui and White, Barry and Bhatti, Jagtar S. and Arp, Paul A.},
  year = {2011},
  month = jul,
  journal = {Ecological Modelling},
  volume = {222},
  number = {14},
  pages = {2314--2332},
  issn = {0304-3800},
  doi = {10.1016/j.ecolmodel.2011.01.003},
  urldate = {2024-05-29},
  abstract = {This article examines the utility of a digitally derived cartographic depth-to-water (DTW) index to model and map variations in drainage, vegetation and soil type and select soil properties within a forested area (40ha) of the Swan Hills, Alberta, Canada. This index was derived from a LiDAR (Light Detection and Ranging) derived digital elevation model (DEM), with at least 1 ground return per m2. The resulting DTW pattern was set to be zero along all DEM-derived flow channels, each with a 4ha flow-initiation threshold. Soil type (luvisol, gleysol, mesisol), drainage type (very poor to excessive), vegetation type (hydric to xeric) and forest floor depth were determined along hillslope transects. These determinations conformed more closely to the DEM-derived log10(DTW) variations (R2{$>$}60\%) than to the corresponding variations of the widely used topographic wetness index (TWI) (R2{$<$}25\%). Setting log10(DTW) thresholds to represent the wet to moist to dry transitions between vegetation, drainage and soil type enabled a high-resolution mapping of these types across the study area. Also determined were soil moisture content, coarse fragment and soil particle composition (sand, silt, clay), pH, total C, N, S, P, Ca, Mg, K, Fe, Al, Mn, Zn, and available Ca, Mg, K, P and NH4, by soil layer type and depth. Most of these variables were also more correlated with log10(DTW) than with TWI, with and without soil layer depth as an additional regression variable. These variables are, therefore, subject to topographic controls to at least some extent, and can be modelled and mapped accordingly, as illustrated for soil moisture, forest floor depth and pH across the study area, from ridge tops to depressions. Further examinations revealed that the DEM-produced DTW and TWI patterns complemented one another, with DTW delineating soils in relation to local water-table influences, and with TWI delineating where the water would flow and accumulate.},
  keywords = {Alberta Foothills,Bare-ground LiDAR DEM,depth-to-water,Physical and chemical soil properties,Soil catena,Soil topo-sequence,Terrain attributes},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Murphy et al. - 2011 - Modelling and mapping topographic variations in fo.pdf}
}

@article{murphyTopographicModellingSoil2009,
  title = {Topographic Modelling of Soil Moisture Conditions: A Comparison and Verification of Two Models},
  shorttitle = {Topographic Modelling of Soil Moisture Conditions},
  author = {Murphy, P. N. C. and Ogilvie, J. and Arp, P.},
  year = {2009},
  journal = {European Journal of Soil Science},
  volume = {60},
  number = {1},
  pages = {94--109},
  issn = {1365-2389},
  doi = {10.1111/j.1365-2389.2008.01094.x},
  urldate = {2024-04-12},
  abstract = {Topography, as captured by a digital elevation model (DEM), can be used to model soil moisture conditions because water tends to flow and accumulate in response to gradients in gravitational potential energy. A widely used topographic index, the soil wetness index (SWI), was compared with a new algorithm that produces a cartographic depth-to-water (DTW) index based on distance to surface water and slope. Both models reflect the tendency for soil to be saturated. A 1 m resolution Light Detection and Ranging (LiDAR) DEM and a 10 m conventional photogrammetric DEM were used and results were compared with field-mapped wet soil areas for a 193 ha watershed in Alberta, Canada, for verification. The DTW model was closer to field-mapped conditions. Values of Kmatch90 (areal correspondence, smaller values indicating better performance) were 7.8\% and 12.3\% for the LiDAR and conventional DEM DTW models, respectively, and 88.5\% and 86.7\% for the SWI models. The two indices were poorly correlated spatially. Both DEMs were found to be useful for modelling soil moisture conditions using the DTW model, but the LiDAR DEM produced the better results. All major wet areas and flow connectivity were reproduced and a threshold value of 1.5 m DTW accounted for 71\% of the observed wet areas. The poor performance of the SWI model is probably because of its over-dependence on flow accumulation. Incorporation of a flow accumulation algorithm that replicates the effects of dispersed flow showed some improvement in the SWI model for the conventional DEM but it still failed to replicate the full areal extent of wet areas. Local downslope topography and hydrologic conditions seemed to be more important in determining soil moisture conditions than is taken account of by the SWI. The DTW model has potential for application in distributed hydrologic modelling, precision forestry and agriculture and implementation of environmental soil management practices.},
  copyright = {{\copyright} 2009 The Authors Journal compilation {\copyright} 2009 British Society of Soil Science},
  langid = {english},
  keywords = {depth-to-water},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Murphy et al. - 2009 - Topographic modelling of soil moisture conditions.pdf}
}

@techreport{ofdalHelicopterborneMagneticRadiometric2015,
  title = {Helicopter-Borne Magnetic and Radiometric Geophysical Survey in {{Romsdalsfjorden}}, {{M{\o}re}} Og {{Romsdal}}},
  author = {Ofdal, Frode},
  year = {2015},
  month = feb,
  number = {2015.015},
  institution = {Geological Survey of Norway},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Ofdal - 2015 - Helicopter-borne magnetic and radiometric geophysi.pdf}
}

@article{olearyDigitalSoilMapping2022,
  title = {Digital Soil Mapping of Peatland Using Airborne Radiometric Data and Supervised Machine Learning -- {{Implication}} for the Assessment of Carbon Stock},
  author = {O'Leary, Dave and Brown, Colin and Daly, Eve},
  year = {2022},
  month = dec,
  journal = {Geoderma},
  volume = {428},
  pages = {116086},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2022.116086},
  urldate = {2022-10-05},
  abstract = {Peatlands account for approx. 4.23 million km2 of the land surface of Earth and between 5\,\% and 20\,\% of the global soil carbon stock, however much uncertainty exists. The release of carbon from modified peatlands is significant and affects the global carbon balance. The importance of conservation and rehabilitation of peatlands is clear. Global estimates currently use national scale mapping strategies that vary depending on available resources and national interest. The most up-to-date methods rely on satellite remote sensing data, which detect peat based on a multiband spectral signature, or reflected radar backscatter. However, satellite data may not be capable of detecting peat under landcover such as pasture or forest. Airborne geophysical surveys provide relevant subsurface information to update or redefine peatland extent maps at a national scale. Radiometric surveys, which measure the naturally occurring geologically sourced potassium, uranium, and thorium, offer the largest potential. Modelling of gamma ray attenuation shows that peat has a distinctive attenuation signature, due to its low bulk density, when considering all recorded radiometric data. This study exploits this signature by combining airborne radiometric data in a machine learning framework and training an artificial neural network to detect those data which have been acquired over previously mapped peatlands. A {$\sim$}95\,\% predictability is achieved. The trained neural network can be then used to predict the extent of all peatlands within a region, including forested and agriculturally modified peatlands, and an updated peatland map can be produced. This methodology has implications for global carbon stock assessment and rehabilitation projects where similar datasets exist or are planned, by updating the extent and boundary positions of current peatlands and uncovering previously unknown peatlands under forestry or grasslands.},
  langid = {english},
  keywords = {artificial neural network,carbon stock,geophysics,inventory,machine learning,peatland},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\O'Leary et al. - 2022 - Digital soil mapping of peatland using airborne ra.pdf}
}

@article{olearyObservationsIntrapeatlandVariability2023,
  title = {Observations of Intra-Peatland Variability Using Multiple Spatially Coincident Remotely Sensed Data Sources and Machine Learning},
  author = {O'Leary, Dave and Brown, Colin and Healy, Mark G. and Regan, Shane and Daly, Eve},
  year = {2023},
  month = feb,
  journal = {Geoderma},
  volume = {430},
  pages = {116348},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2023.116348},
  urldate = {2023-02-06},
  abstract = {Peatlands are important sites of ecosystem services, particularly as soil carbon stores, and are recognised in many international climate strategies. However, drained peatlands, which have been modified for industrial extraction or agriculture, are responsible for carbon emission. Peatland restoration aims to return these degraded sites to a natural state. Multiple means of remotely monitoring the success of peat restoration are available, ranging from space-based satellite measurements (optical and radar) to airborne geophysical measurements (electro-magnetic and radiometric). This paper integrates multi-band, spatially coincident, remotely sensed data into a single framework, resulting in a comprehensive interpretation of intra-peatland variation of key restoration indicators. It uses a semi-automatic, data driven approach with unsupervised neural network machine learning clustering. A Multi-Cluster Average Standard Deviation metric is introduced which can determine the appropriate number of clusters for any dataset. The method was applied to a site in Ireland, representative of degraded peatlands, where optical satellite and airborne radiometric geophysical measurements were combined. The method was successful at determining the appropriate number of clusters for single and combined datasets, and the resulting cluster signatures provided visually compelling representations of the intra-peatland variation. This resulted in a comprehensive interpretation of intra-peatland variation of several key peatland restoration indicators, namely surface vegetation levels and soil moisture to~{$\sim~$}60~cm of the peat surface. The study provides a framework for high spatial and temporal resolution monitoring of peatland restoration using future drone-based platforms.},
  langid = {english},
  keywords = {classification,clustering,geophysics,machine learning,peatland,radiometry,remote sensing,restoration},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\O'Leary et al. - 2023 - Observations of intra-peatland variability using m.pdf}
}

@article{olteanLinkingDepthtoWaterTopographic2016,
  title = {Linking the {{Depth-to-Water Topographic Index}} to {{Soil Moisture}} on {{Boreal Forest Sites}} in {{Alberta}}},
  author = {Oltean, Gabriel S and Comeau, Philip G and White, Barry},
  year = {2016},
  abstract = {The depth-to-water (DTW) index is defined as the cumulative slope along the least-cost pathway from any cell in the landscape to the nearest flow channel. The flow channel network is determined by the flow initiation area selected, allowing the representation of various geological and topographical attributes of the landscape. We used data from 125 plots across five locations in the boreal forest of Alberta, Canada, to evaluate the following: the relationships between soil attributes and DTW; the optimal flow initiation area; and models to map the spatial variation of soil properties. Soil moisture regime (SMR), drainage class, and depth-to-mottles were strongly related with DTW, whereas soil nutrient regime, organic matter thickness, soil texture, and coarse fragment content exhibited weak and inconsistent relationships with DTW. A flow initiation area of 2 ha yielded the best representation for SMR, drainage class, and depth-to-mottles. DTW, flow accumulation (FA) and local slope were combined in a linear model to estimate and map SMR, whereas only DTW and FA were used to model drainage and depth-to-mottles. These results suggest that the DTW index can capture soil properties closely influenced by the water table but cannot characterize site and soil factors, which are also determined by parent material, climate, and vegetation.},
  langid = {english},
  keywords = {depth-to-water},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Oltean et al. - 2016 - Linking the Depth-to-Water Topographic Index to So.pdf}
}

@article{parryMethodModellingPeat2012,
  title = {A Method for Modelling Peat Depth in Blanket Peatlands},
  author = {Parry, L. E. and Charman, D. J. and Noades, J. P. W.},
  year = {2012},
  journal = {Soil Use and Management},
  volume = {28},
  number = {4},
  pages = {614--624},
  issn = {1475-2743},
  doi = {10.1111/j.1475-2743.2012.00447.x},
  urldate = {2020-03-20},
  abstract = {Inventories of peat volume and carbon storage often include general values for peat depth, but more spatially explicit and accurate estimates are required if carbon management strategies are to be developed at scales appropriate for the management. This article presents a methodology for estimating peat depth for large blanket peat areas using field sampling and GIS modelling to map peat depth on Dartmoor in south-west England. The study area was divided into carbon unit areas (CUAs) based on soil and vegetation. Approximately 1000 peat depth measurements were taken, each consisting of a mean (n = 5) from depths within a 32 m2 area. Sampling points were stratified according to CUA area and proportional extent of slope and elevation classes. Regression analyses were used to determine the relationships between slope, elevation and peat depth within each CUA. The strongest relationship was for blanket peat (r2 = 0.53), with weaker ones for areas where peat was shallow and depth was less variable. A digital elevation model was used in a GIS to model peat depths for the whole of Dartmoor. Results were tested against a data set of 200 peat depths on a 250 m grid covering 1325 ha. We conclude that peat depth can be modelled using easily available topographic data combined with well-designed field sampling over larger spatial scales. The approach can result in accurate mapping of peat depth and carbon storage for blanket peatlands in the United Kingdom and perhaps also elsewhere.},
  copyright = {{\copyright} 2012 The Authors. Journal compilation {\copyright} 2012 British Society of Soil Science},
  langid = {english},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Parry et al. - 2012 - A method for modelling peat depth in blanket peatl.pdf}
}

@article{probstHyperparametersTuningStrategies2019,
  title = {Hyperparameters and Tuning Strategies for Random Forest},
  author = {Probst, Philipp and Wright, Marvin N. and Boulesteix, Anne-Laure},
  year = {2019},
  journal = {WIREs Data Mining and Knowledge Discovery},
  volume = {9},
  number = {3},
  pages = {e1301},
  issn = {1942-4795},
  doi = {10.1002/widm.1301},
  urldate = {2024-04-09},
  abstract = {The random forest (RF) algorithm has several hyperparameters that have to be set by the user, for example, the number of observations drawn randomly for each tree and whether they are drawn with or without replacement, the number of variables drawn randomly for each split, the splitting rule, the minimum number of samples that a node must contain, and the number of trees. In this paper, we first provide a literature review on the parameters' influence on the prediction performance and on variable importance measures. It is well known that in most cases RF works reasonably well with the default values of the hyperparameters specified in software packages. Nevertheless, tuning the hyperparameters can improve the performance of RF. In the second part of this paper, after a presenting brief overview of tuning strategies, we demonstrate the application of one of the most established tuning strategies, model-based optimization (MBO). To make it easier to use, we provide the tuneRanger R package that tunes RF with MBO automatically. In a benchmark study on several datasets, we compare the prediction performance and runtime of tuneRanger with other tuning implementations in R and RF with default hyperparameters. This article is categorized under: Algorithmic Development {$>$} Biological Data Mining Algorithmic Development {$>$} Statistics Algorithmic Development {$>$} Hierarchies and Trees Technologies {$>$} Machine Learning},
  copyright = {{\copyright} 2019 Wiley Periodicals, Inc.},
  langid = {english},
  keywords = {ensemble,literature review,out-of-bag,performance evaluation,ranger,sequential model-based optimization,tuning parameter},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Probst et al. - 2019 - Hyperparameters and tuning strategies for random f.pdf}
}

@article{rahmanNewMethodMap2017,
  title = {A {{New Method}} to {{Map Groundwater Table}} in {{Peatlands Using Unmanned Aerial Vehicles}}},
  author = {Rahman, Mir Mustafizur and McDermid, Gregory J. and Strack, Maria and Lovitt, Julie},
  year = {2017},
  month = oct,
  journal = {Remote Sensing},
  volume = {9},
  number = {10},
  pages = {1057},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs9101057},
  urldate = {2024-05-29},
  abstract = {Groundwater level (GWL) and depth to water (DTW) are related metrics aimed at characterizing groundwater-table positions in peatlands, and two of the most common variables collected by researchers working in these ecosystems. While well-established field techniques exist for measuring GWL and DTW, they are generally difficult to scale. In this study, we present a novel workflow for mapping groundwater using orthophotography and photogrammetric point clouds acquired from unmanned aerial vehicles. Our approach takes advantage of the fact that pockets of surface water are normally abundant in peatlands, which we assume to be reflective of GWL in these porous, gently sloping environments. By first classifying surface water and then extracting a sample of water elevations, we can generate continuous models of GWL through interpolation. Estimates of DTW can then be obtained through additional efforts to characterize terrain. We demonstrate our methodology across a complex, 61-ha treed bog in northern Alberta, Canada. An independent accuracy assessment using 31 temporally coincident water-well measurements revealed accuracies (root mean square error) in the 20-cm range, though errors were concentrated in small upland pockets in the study area, and areas of dense tree covers. Model estimates in the open peatland areas were considerably better.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {groundwater table,peatland,photogrammetry,remote sensing,spatial interpolation,UAV},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Rahman et al. - 2017 - A New Method to Map Groundwater Table in Peatlands.pdf}
}

@misc{RegjeringenGir50,
  title = {Regjeringen Gir 50 Millioner Til Naturkart Etter {{NRKs}} Avsl{\o}ringer -- {{NRK Dokumentar}}},
  urldate = {2024-09-06},
  howpublished = {https://www.nrk.no/dokumentar/regjeringen-gir-50-millioner-til-naturkart-etter-nrks-avsloringer-1.17023767},
  file = {C:\Users\julienv\Zotero\storage\HEKS8ZJ3\regjeringen-gir-50-millioner-til-naturkart-etter-nrks-avsloringer-1.html}
}

@article{robertsCrossvalidationStrategiesData2017,
  title = {Cross-Validation Strategies for Data with Temporal, Spatial, Hierarchical, or Phylogenetic Structure},
  author = {Roberts, David R. and Bahn, Volker and Ciuti, Simone and Boyce, Mark S. and Elith, Jane and {Guillera-Arroita}, Gurutzeta and Hauenstein, Severin and {Lahoz-Monfort}, Jos{\'e} J. and Schr{\"o}der, Boris and Thuiller, Wilfried and Warton, David I. and Wintle, Brendan A. and Hartig, Florian and Dormann, Carsten F.},
  year = {2017},
  month = aug,
  journal = {Ecography},
  volume = {40},
  number = {8},
  pages = {913--929},
  publisher = {Wiley/Blackwell (10.1111)},
  issn = {09067590},
  doi = {10.1111/ecog.02881},
  urldate = {2018-06-29},
  keywords = {autocorrelation,cross validation,extrapolation,model performance,overfitting},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Roberts et al_2017_Cross-validation strategies for data with temporal, spatial, hierarchical, or.pdf}
}

@incollection{roudierConditionedLatinHypercube2012,
  title = {A Conditioned {{Latin}} Hypercube Sampling Algorithm Incorporating Operational Constraints},
  booktitle = {Digital Soil Assessments and Beyond},
  author = {Roudier, Pierre and Beaudette, {\relax DE} and Hewitt, {\relax AE}},
  year = {2012},
  pages = {227--231},
  publisher = {CRC Press London},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Roudier et al. - 2012 - A conditioned Latin hypercube sampling algorithm i.pdf}
}

@article{rudiyantoOpenDigitalMapping2018,
  title = {Open Digital Mapping as a Cost-Effective Method for Mapping Peat Thickness and Assessing the Carbon Stock of Tropical Peatlands},
  author = {{Rudiyanto} and Minasny, B. and Setiawan, B.I. and Saptomo, S.K. and McBratney, A.B.},
  year = {2018},
  journal = {Geoderma},
  volume = {313},
  pages = {25--40},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2017.10.018},
  abstract = {Tropical peatland holds a large amount of carbon in the terrestrial ecosystem. Indonesia, responding to the global climate issues, has legislation on the protection and management of the peat ecosystem. However, this effort is hampered by the lack of fine-scale, accurate maps of peat distribution and its thickness. This paper presents an open digital mapping methodology, which utilises open data in an open-source computing environment, as a cost-effective method for mapping peat thickness and estimating carbon stock in Indonesian peatlands. The digital mapping methodology combines field observations with factors that are known to influence peat thickness distribution. These factors are represented by multi-source remotely-sensed data derived from open and freely available raster data: digital elevation models (DEM) from SRTM, geographical information, and radar images (Sentinel and ALOS PALSAR). Utilising machine-learning models from an open-source software, we derived spatial prediction functions and mapped peat thickness and its uncertainty at a grid resolution of 30 m. Peat volume can be calculated from the thickness map, and based on measurements of bulk density and carbon content, carbon stock for the area was estimated. The uncertainty of the estimates was calculated using error propagation rules. We demonstrated this approach in the eastern part of Bengkalis Island in Riau Province, covering an area around 50,000 ha. Results showed that digital mapping method can accurately predict the thickness of peat, explaining up to 98\% of the variation of the data with a median relative error of 5\% or an average error of 0.3 m. The accuracy of this method depends on the number of field observations. We provided an estimate of the cost and time required for map production, i.e. 2 to 4 months with a cost between \$0.3 and \$0.5/ha for an area of 50,000 ha. Obviously, there is a tradeoff between cost and accuracy. The advantages and limitations of the method were further discussed. The methodology provides a blueprint for a national-scale peat mapping. {\copyright} 2017 Elsevier B.V.},
  langid = {english},
  keywords = {open data,open source,peatland},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Rudiyanto et al_2018_Open digital mapping as a cost-effective method for mapping peat thickness and.pdf}
}

@article{sauretteDeterminingMinimumSample2022,
  title = {Determining Minimum Sample Size for the Conditioned {{Latin}} Hypercube Sampling Algorithm},
  author = {Saurette, Daniel D. and Biswas, Asim and Heck, Richard J. and Gillespie, Adam W. and Berg, Aaron A.},
  year = {2022},
  month = sep,
  journal = {Pedosphere},
  issn = {1002-0160},
  doi = {10.1016/j.pedsph.2022.09.001},
  urldate = {2023-06-12},
  abstract = {In digital soil mapping (DSM), a fundamental assumption is that the spatial variability of the target variable can be explained by the predictors or environmental covariates. Strategies to adequately sample the predictors have been well documented, with the conditioned Latin Hypercube Sampling (cHLS) algorithm receiving the most attention in the DSM community. Despite advances in sampling design, a critical gap remains in determining the number of samples required for a DSM project. We propose a simple workflow and function coded in R language, to determine the minimum sample size for the cLHS algorithm based on histograms of the predictor variables using the Freedman-Diaconis rule for determining optimal bin width. Data pre-processing was included to correct for multimodal and non-normally distributed data, since these can affect sample size determination from the histogram. Based on a user-selected confidence interval (CI) for the sample plan, the density of the histogram bins at the upper and lower bounds of the CI are used as a scaling factor to then determine minimum sample size. The technique is applied to a field-scale set of environmental covariates for a well sampled agricultural study site near Guelph, Ontario, Canada, and tested across a range of CIs. The results showed increasing minimum sample size with an increase in the CI selected. Minimum sample size increased from 44 to 83 samples when the CI increased from 50\% to 95\%, then increased exponentially to 194 samples for the 99\% CI. The technique provided an estimate of minimum sample size that can then be used as an input to the cLHS algorithm.},
  langid = {english},
  keywords = {conditioned Latin hypercube,digital soil mapping,LHS,normal distribution,sample size,sampling design},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Saurette et al. - 2022 - Determining minimum sample size for the conditione.pdf}
}

@article{sauretteDivergenceMetricsDetermining2023,
  title = {Divergence Metrics for Determining Optimal Training Sample Size in Digital Soil Mapping},
  author = {Saurette, Daniel D. and Heck, Richard J. and Gillespie, Adam W. and Berg, Aaron A. and Biswas, Asim},
  year = {2023},
  month = aug,
  journal = {Geoderma},
  volume = {436},
  pages = {116553},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2023.116553},
  urldate = {2023-06-02},
  abstract = {Digital soil mapping (DSM) typically requires three common ingredients: georeferenced samples, environmental covariates, and a model. Of the three, sample design, or the selection of sample size and locations, has received considerably less attention. This is not surprising given that most studies are primarily limited by budget, the result being a focus on stratification of sampling locations in covariate (feature) space with less emphasis placed on the sample size. At the very least, determining the optimal sample size, regardless of whether it is achievable within a given budget, provides critical information about the loss of information from not collecting enough samples for a given study area. In this study, we evaluated the use of the Kullback-Leibler divergence (DKL), the Jensen-Shannon divergence (DJS), the Jenson-Shannon distance (DistJS), and the normalized variance in determining an optimal sample size for predicting total soil carbon at the field scale. The divergence metrics were computed for replicated (n~=~10) sample plans using the conditioned Latin hypercube sampling algorithm across increasing samples sizes of 10, 25, and 50 to 400 in steps of 50 to determine an optimal sample size; the sensitivity of the divergence metrics to increasing the number of covariates and the number of bins for their computations were evaluated. The random forest algorithm was used to train predictive models using the same replicated sample sizes to determine the required sample size to optimize model performance based on root mean square error and Lin's concordance correlation coefficient. The divergence metrics were insensitive to the number of covariates, but very sensitive to the number of bins specified for their calculation. On average, optimal sample size increased linearly (two additional samples per additional bin) regardless of the number of covariates used. The optimal sample sizes were 124, 133 and 220 for the DKL, DJS and DistJS divergence metrics, respectively, while the variance technique proved to be unreliable. Based on the model performance metrics from model validation, the optimal sample size ranged from 146 to 154 samples. The DistJS overestimated the optimal sample size considerably, while the DKL and DJS were quite similar to the optimal sample size determined from model validation. Future work should evaluate the use of divergence metrics for determining optimal sample size for multiple soil properties or classes, using various machine learning models, across different project scales, and with other sampling algorithms.},
  langid = {english},
  keywords = {Conditioned Latin hypercube,digital soil mapping,Divergence,Jensen-Shannon,Kullback-Leibler,LHS,random forest,sample size,sampling design},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Saurette et al. - 2023 - Divergence metrics for determining optimal trainin.pdf}
}

@misc{schonauerRcodeCalculatingDepthtowater2021,
  title = {R-Code for Calculating Depth-to-Water ({{DTW}}) Maps Using {{GRASS GIS}}},
  author = {Sch{\"o}nauer, Marian and Maack, Joachim},
  year = {2021},
  month = nov,
  publisher = {Zenodo},
  doi = {10.5281/zenodo.5718133},
  urldate = {2024-04-11},
  abstract = {The depth-to-water (DTW) concept was conceived, developed and tested at the University of New Brunswick (Faculty of Forestry and Environmental Management), by Fan-Rui Meng, Jae Ogilvie and Paul Arp, as described by, e.g., Murphy et al. (2007; 2009). This R-code was developed by Marian Sch{\"o}nauer and Joachim Maack.},
  archiveprefix = {Zenodo},
  langid = {english},
  keywords = {depth-to-water,soil moisture},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Schönauer and Maack - 2021 - R-code for calculating depth-to-water (DTW) maps u.pdf}
}

@article{schonauerSpatiotemporalPredictionSoil2021,
  title = {Spatio-Temporal Prediction of Soil Moisture and Soil Strength by Depth-to-Water Maps},
  author = {Sch{\"o}nauer, Marian and V{\"a}{\"a}t{\"a}inen, Kari and Prinz, Robert and Lindeman, Harri and Pszenny, Dariusz and Jansen, Martin and Maack, Joachim and Talbot, Bruce and Astrup, Rasmus and Jaeger, Dirk},
  year = {2021},
  month = dec,
  journal = {International Journal of Applied Earth Observation and Geoinformation},
  volume = {105},
  pages = {102614},
  issn = {1569-8432},
  doi = {10.1016/j.jag.2021.102614},
  urldate = {2024-05-29},
  abstract = {The utilization of detailed digital terrain models entails an enhanced basis for supporting sustainable forest management, including the reduction of soil impacts through predictions of site trafficability during mechanized harvesting operations. Since wet soils are prone to traffic-induced damages, soil moisture is incorporated into several systems for spatial predictions of trafficability. Yet, only few systems consider temporal dynamics of soil moisture, impeding the accuracy and practical value of predictions. The depth-to-water (DTW) algorithm calculates a cartographic index which indicates wet areas. Temporal dynamics of soil moisture are simulated by different DTW map-scenarios derived from set flow initiation areas (FIA). However, the concept of simulating seasonal moisture conditions by DTW map-scenarios was not analyzed so far. Therefore, we conducted field campaigns at six study sites across Europe, capturing time-series of soil moisture and soil strength along several transects which crossed predicted wet areas. Assuming overall dry conditions (FIA~=~4.00~ha), DTW predicted 20\% of measuring points to be wet. When a FIA of 1.00~ha (moist conditions) or 0.25~ha (wet conditions) were applied, DTW predicted 29\% or 58\% of points to be wet, respectively. De facto, 82\% of moisture measurements were predicted correctly by the map-scenario for overall dry conditions -- with 44\% of wet measurements deviating from predictions made. The prediction of soil strength was less successful, with 66\% of low values occurring on areas where DTW indicated dryer soils and subsequently a sufficient trafficability. The condition-specific usage of different map-scenarios did not improve the accuracy of predictions, as compared to static map-scenarios, chosen for each site. We assume that site-specific and non-linear hydrological processes compromise the generalized assumptions of simulating overall moisture conditions by different FIA.},
  keywords = {depth-to-water,Depth-to-water,Forest operations,Precision forestry,Soil bearing capacity,Soil moisture content,Trafficability prediction},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Schönauer et al. - 2021 - Spatio-temporal prediction of soil moisture and so.pdf}
}

@article{schratzHyperparameterTuningPerformance2019,
  title = {Hyperparameter Tuning and Performance Assessment of Statistical and Machine-Learning Algorithms Using Spatial Data},
  author = {Schratz, Patrick and Muenchow, Jannes and Iturritxa, Eugenia and Richter, Jakob and Brenning, Alexander},
  year = {2019},
  month = aug,
  journal = {Ecological Modelling},
  volume = {406},
  pages = {109--120},
  issn = {0304-3800},
  doi = {10.1016/j.ecolmodel.2019.06.002},
  urldate = {2024-08-16},
  abstract = {While the application of machine-learning algorithms has been highly simplified in the last years due to their well-documented integration in commonly used statistical programming languages (such as R or Python), there are several practical challenges in the field of ecological modeling related to unbiased performance estimation. One is the influence of spatial autocorrelation in both hyperparameter tuning and performance estimation. Grouped cross-validation strategies have been proposed in recent years in environmental as well as medical contexts to reduce bias in predictive performance. In this study we show the effects of spatial autocorrelation on hyperparameter tuning and performance estimation by comparing several widely used machine-learning algorithms such as boosted regression trees (BRT), k-nearest neighbor (KNN), random forest (RF) and support vector machine (SVM) with traditional parametric algorithms such as logistic regression (GLM) and semi-parametric ones like generalized additive models (GAM) in terms of predictive performance. Spatial and non-spatial cross-validation methods were used to evaluate model performances aiming to obtain bias-reduced performance estimates. A detailed analysis on the sensitivity of hyperparameter tuning when using different resampling methods (spatial/non-spatial) was performed. As a case study the spatial distribution of forest disease (Diplodia sapinea) in the Basque Country (Spain) was investigated using common environmental variables such as temperature, precipitation, soil and lithology as predictors. Random Forest (mean Brier score estimate of 0.166) outperformed all other methods with regard to predictive accuracy. Though the sensitivity to hyperparameter tuning differed between the ML algorithms, there were in most cases no substantial differences between spatial and non-spatial partitioning for hyperparameter tuning. However, spatial hyperparameter tuning maintains consistency with spatial estimation of classifier performance and should be favored over non-spatial hyperparameter optimization. High performance differences (up to 47\%) between the bias-reduced (spatial cross-validation) and overoptimistic (non-spatial cross-validation) cross-validation settings showed the high need to account for the influence of spatial autocorrelation. Overoptimistic performance estimates may lead to false actions in ecological decision making based on biased model predictions.},
  keywords = {Hyperparameter tuning,Machine-learning,Spatial autocorrelation,Spatial cross-validation,Spatial modeling},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Schratz et al. - 2019 - Hyperparameter tuning and performance assessment o2.pdf}
}

@article{schweigerOptimizingSamplingApproaches2016,
  title = {Optimizing Sampling Approaches along Ecological Gradients},
  author = {Schweiger, Andreas H. and Irl, Severin D. H. and Steinbauer, Manuel J. and Dengler, J{\"u}rgen and Beierkuhnlein, Carl},
  year = {2016},
  journal = {Methods in Ecology and Evolution},
  volume = {7},
  number = {4},
  pages = {463--471},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.12495},
  urldate = {2023-05-09},
  abstract = {Natural scientists and especially ecologists use manipulative experiments or field observations along gradients to differentiate patterns driven by processes from those caused by random noise. A well-conceived sampling design is essential for identifying, analysing and reporting underlying patterns in a statistically solid and reproducible manner, given the normal restrictions in labour, time and money. However, a technical guideline about an adequate sampling design to maximize prediction success under restricted resources is lacking. This study aims at developing such a solid and reproducible guideline for sampling along gradients in all fields of ecology and science in general. We conducted simulations with artificial data for five common response types known in ecology, each represented by a simple function (no response, linear, exponential, symmetric unimodal and asymmetric unimodal). In the simulations, we accounted for different levels of random and systematic error, the two sources of noise in ecological data. We quantified prediction success for varying total sample size, number of locations sampled along a spatial/temporal gradient and number of replicates per sampled location. The number of replicates becomes more important with increasing random error, whereas replicates become less relevant for a systematic error bigger than 20\% of total variation. Thus, if high levels of systematic error are indicated or expected (e.g. in field studies with spatial autocorrelation, unaccountable additional environmental drivers or population clustering), continuous sampling with little to no replication is recommended. In contrast, sampling designs with replications are recommended in studies that can control for systematic errors. In a setting that is characteristic for ecological experiments and field studies strictly controlling for undeterminable systematic error (random error {$\geq$}10\% and systematic error {$\leq$}10\% of total variation), prediction success was best for an intermediate number of sampled locations along the gradient (10--15) and a low number of replicates per location (3). Our findings from reproducible, statistical simulations will help design appropriate and efficient sampling approaches and avoid erroneous conclusions based on studies with flawed sampling design, which is currently one of the main targets of public criticism against science.},
  langid = {english},
  keywords = {anova,curve fitting,ecological experiment,experimental design,model selection,regression analysis,replication,sampling design,simulation},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Schweiger et al. - 2016 - Optimizing sampling approaches along ecological gr.pdf}
}

@article{sekulicRandomForestSpatial2020,
  title = {Random {{Forest Spatial Interpolation}}},
  author = {Sekuli{\'c}, Aleksandar and Kilibarda, Milan and Heuvelink, Gerard B. M. and Nikoli{\'c}, Mladen and Bajat, Branislav},
  year = {2020},
  month = jan,
  journal = {Remote Sensing},
  volume = {12},
  number = {10},
  pages = {1687},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs12101687},
  urldate = {2023-06-21},
  abstract = {For many decades, kriging and deterministic interpolation techniques, such as inverse distance weighting and nearest neighbour interpolation, have been the most popular spatial interpolation techniques. Kriging with external drift and regression kriging have become basic techniques that benefit both from spatial autocorrelation and covariate information. More recently, machine learning techniques, such as random forest and gradient boosting, have become increasingly popular and are now often used for spatial interpolation. Some attempts have been made to explicitly take the spatial component into account in machine learning, but so far, none of these approaches have taken the natural route of incorporating the nearest observations and their distances to the prediction location as covariates. In this research, we explored the value of including observations at the nearest locations and their distances from the prediction location by introducing Random Forest Spatial Interpolation (RFSI). We compared RFSI with deterministic interpolation methods, ordinary kriging, regression kriging, Random Forest and Random Forest for spatial prediction (RFsp) in three case studies. The first case study made use of synthetic data, i.e., simulations from normally distributed stationary random fields with a known semivariogram, for which ordinary kriging is known to be optimal. The second and third case studies evaluated the performance of the various interpolation methods using daily precipitation data for the 2016--2018 period in Catalonia, Spain, and mean daily temperature for the year 2008 in Croatia. Results of the synthetic case study showed that RFSI outperformed most simple deterministic interpolation techniques and had similar performance as inverse distance weighting and RFsp. As expected, kriging was the most accurate technique in the synthetic case study. In the precipitation and temperature case studies, RFSI mostly outperformed regression kriging, inverse distance weighting, random forest, and RFsp. Moreover, RFSI was substantially faster than RFsp, particularly when the training dataset was large and high-resolution prediction maps were made.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {daily precipitation,daily temperature,kriging,machine learning,random forest,spatial interpolation},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Sekulić et al. - 2020 - Random Forest Spatial Interpolation.pdf}
}

@article{shaoSampleDesignOptimization2022,
  title = {Sample Design Optimization for Soil Mapping Using Improved Artificial Neural Networks and Simulated Annealing},
  author = {Shao, Shuangshuang and Su, Baowei and Zhang, Yalu and Gao, Chao and Zhang, Ming and Zhang, Huan and Yang, Lin},
  year = {2022},
  month = may,
  journal = {Geoderma},
  volume = {413},
  pages = {115749},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2022.115749},
  urldate = {2023-06-21},
  abstract = {Optimization of the sampling design is significant for generating accurate soil maps based on samples. Simulated annealing (SA) with the mean squared prediction error (MSE) as objective function has been proven as an effective method for sampling optimization with prior samples for the MSE calculation. In this study, an improved artificial neural network (the improved ANN) was developed firstly and then utilized to calculate the objective function of SA for sampling optimization (named as the improved ANN\_SA). The proposed approach was evaluated to generate optimized samples with a series of samples sizes (from 10 to 500 points) for mapping soil organic matter (SOM) content from the existing 5054 samples in a study area with 1067~km2 in Jiangsu Province, China. A commonly-used sampling optimization using SA with the objective function calculated by regression kriging (named as RK\_SA) was taken as a reference method. The two sampling optimization approaches were compared in mapping SOM using three prediction methods, the improved ANN, regression kriging (RK) and random forest. The results showed that the proposed sampling optimization approach generally achieved more accurate prediction over different sampling sizes. The maximum improvement of prediction accuracy by using the proposed sampling strategy vs. the reference strategy was 12.5\%, 53.6\%, and 15.5\% when using the improved ANN, RK, and random forest as soil mapping methods, respectively. Moreover, the improved ANN and random forest generated more accurate soil predictions than RK with the proposed sampling optimization approach. The superiority of the proposed sampling optimization was more obvious in low sampling densities (smaller than 0.3 points/km2). We conclude that the improved ANN\_SA sampling is a potential effective sampling optimization approach, and machine learning is a promising method for soil mapping when using this sampling approach.},
  langid = {english},
  keywords = {neural network,Sampling optimization,Simulated annealing,Soil mapping,Soil organic matter},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Shao et al. - 2022 - Sample design optimization for soil mapping using .pdf}
}

@article{sharyFundamentalQuantitativeMethods2002,
  title = {Fundamental Quantitative Methods of Land Surface Analysis},
  author = {Shary, Peter A and Sharaya, Larisa S and Mitusov, Andrew V},
  year = {2002},
  month = may,
  journal = {Geoderma},
  volume = {107},
  number = {1},
  pages = {1--32},
  issn = {0016-7061},
  doi = {10.1016/S0016-7061(01)00136-7},
  urldate = {2024-04-11},
  abstract = {Effective quantitative land surface analyses in soil science need scale-free land surface attributes (morphometric variables, MVs) to be introduced for making comparable results obtained at different scales. To investigate the problem in more detail, a conceptual scheme and curvatures studied earlier in Shary (1995) [Math. Geol. 27 (1995) 373] are further developed in this paper, formulae for a complete system of 12 curvatures and some other MVs are given, and modified Evans--Young algorithm for curvature calculation is described that does not emphasize grid directions. The conceptual scheme is based on that MVs often describe not the land surface itself, but rather the system ``land surface+vector field'', where vector fields of common interest are gravitational field and solar irradiation. Correspondingly, morphometric variables and concepts may (1) refer to this system description (field-specific), or (2) be invariant with respect to any vector field (field-invariant), that is, describing the land surface itself, its geometrical form. From the other side, MVs and concepts may be (1) local, (2) regional, which need extended portions of a restricted part of land surface for their determination at a given point, or (3) global (planetary), when elevations of all the Earth are needed for their determination at a given point. Global MVs do not consist subject of this paper; so, the four classes of MVs are considered here: class A (local field-specific MVs), class B (regional field-specific), class C (local field-invariant), and class D (regional field-invariant). MVs of these classes permit description of geometrical land form, pre-requisits of surface runoff, thermal regime of slopes, and altitude zonality. Class A contains three independent MVs expressed by first derivatives of elevation Z by plan coordinates (slope steepness, slope direction, solar insolation) and seven curvatures expressed by second derivatives of Z; class C contains five curvatures; class B contains two variables (catchment and dispersal areas); MVs of class D are not introduced yet. Also, some non-system MVs of class A are described, sense of all MVs is described, and interrelationships between MVs are shown. Three curvatures are independent, not two, as this is often implied. It is experimentally shown that average depth of a depression defined in class B may not depend upon scale, while local MVs may not have limit values for large scales. Scale-free morphometric variables are defined here as those that have limit values for large scales. It is experimentally shown that maximal catchment area (class B) is a scale-free variable for thalwegs. These results show that local MVs are scale-specific (except elevation), but scale-free regional MVs might be introduced as a generalization of curvature concept. Two surface runoff accumulation mechanisms are considered in their relation to local and regional field-specific MVs; although the first one is generalized to a regional MV (catchment area), there is no regional MV for the second one description, although it is of great importance in soil science as describing slow profile changes. Geometrical forms were little studied in soil science; arguments are given that they may be useful for studying memory in soils, which is determined by temporal shifts between land surface formation and soil formation processes. The following topics are discussed: the current state of morphometry, an ambiguity in land form definitions, and a possibility to generalize curvature concept for regional scale-free MVs. The consideration is restricted by methods of the general geomorphometry; partial approaches are considered only by selection.},
  keywords = {Curvature,Digital elevation model,Invariant,Runoff,Scale,Topography},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Shary et al. - 2002 - Fundamental quantitative methods of land surface a.pdf}
}

@article{siemonAirborneElectromagneticRadiometric2020,
  title = {Airborne Electromagnetic and Radiometric Peat Thickness Mapping of a Bog in Northwest {{Germany}} ({{Ahlen-Falkenberger}} Moor)},
  author = {Siemon, Bernhard and {Ibs-von Seht}, Malte and Frank, Stefan},
  year = {2020},
  month = jan,
  journal = {Remote Sensing},
  volume = {12},
  number = {2},
  pages = {203},
  publisher = {Mdpi},
  address = {Basel},
  doi = {10.3390/rs12020203},
  urldate = {2021-11-17},
  abstract = {Knowledge on peat volumes is essential to estimate carbon stocks accurately and to facilitate appropriate peatland management. This study used airborne electromagnetic and radiometric data to estimate the volume of a bog. Airborne methods provide an alternative to ground-based methods, which are labor intensive and unfeasible to capture large-scale ({$>$}10 km(2)) spatial information. An airborne geophysical survey conducted in 2004 covered large parts of the Ahlen-Falkenberger Moor, an Atlantic peat bog (39 km(2)) close to the German North Sea coast. The lateral extent of the bog was derived from low radiometric and elevated surface data. The vertical extent resulted from smooth resistivity models derived from 1D inversion of airborne electromagnetic data, in combination with a steepest gradient approach, which indicated the base of the less resistive peat. Relative peat thicknesses were also derived from decreasing radiation over peatlands. The scaling factor (mu(a) = 0.28 m(-1)) required to transform the exposure rates (negative log-values) to thicknesses was calculated using the electromagnetic results as reference. The mean difference of combined airborne results and peat thicknesses of about 100 boreholes is very small (0.0 +/- 1.1 m). Although locally some (5\%) deviations ({$>$}2 m) from the borehole results do occur, the approach presented here enables fast peat volume mapping of large areas without an imperative necessity of borehole data.},
  langid = {english},
  keywords = {digital soil mapping,peat,peatland,radiometry,remote sensing},
  annotation = {WOS:000515569800002},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Siemon et al_2020_Airborne Electromagnetic and Radiometric Peat Thickness Mapping of a Bog in.pdf}
}

@techreport{silvennoinenRoadmapGeneratingSoil2023,
  title = {{Roadmap for generating a soil map for Norwegian pristine mires}},
  author = {Silvennoinen, Hanna and Venter, Zander and Hansen, Jenny and Fandrem, Marte and Lunde, Linn Marie and Lyngstad, Anders and Kyrkjeeide, Magni Olsen and A'Campo, Willeke},
  year = {2023},
  journal = {26},
  institution = {Norsk institutt for naturforskning (NINA)},
  issn = {1504-3312},
  urldate = {2023-12-18},
  abstract = {Silvennoinen, H., Venter, Z., Hansen, J., Fandrem, M., Lunde, L.M., Lyngstad, A., Kyrkjeeide, M.O., A'Campo, W. \& Nilsen, E. 2023. Roadmap for generating a soil map for Norwegian pristine mires. NINA Report 2374. Norwegian Institute for Nature Research.   Under the umbrella of larger project `{\O}kologik tilstand', we created a roadmap for mapping soil biogeochemistry of Norwegian mires. Mapping soil characteristics, especially carbon and nitrogen stocks as well as their other chemical parameters, as well as physical and biological variables is important to better understand the consequences of various planned disturbances as well as their magnitude.\,\,\,   We searched for the availability of existing Norwegian contemporary and historical data to characterize future data requirements and to test predictive models applying remote sensing tools. To the date, only two datasets are available: a small limited contemporary data set published in Kyrkjeeide et al. (2023) and a large historical dataset collected by `Myrselskapet' (Hovde 1971) and published and stored by NIBIO.   We digitalized and georeferenced this historical dataset, which is now published in Living Norway (Silvennoinen et al. 2023). The consists of various types of peatlands including drained and pristine and used selected parts of it to test the predictive models for mapping carbon and nitrogen densities. This was done as a pilot project to explore the potential for remote sensing and spatial modelling to monitor Norwegian mires. Our pilot study revealed that although we could map carbon and nitrogen densities, the models were attributed with large uncertainties. The models explained between 22 and 24\% of the variance in carbon and nitrogen densities. This highlights the need for gathering contemporary in-situ field data for training and ground-truthing remote sensing models before they can be used for developing national soil maps for mires. The limited amount of `Myrselskapet' data which is spatially biased (ie. concentrated in selected areas in Norway) combined with data age (between 61 and 85 years old) makes spatial modelling of mire geochemistry challenging. The dataset is also limited in the amount of data for critical variables, namely peat depth, in order to compute carbon and nitrogen stocks reliably.\,   Ongoing national soil monitoring programs concentrate on agricultural (JORVAAK - program) and forest soils (`Overv{\aa}king av jordkarbon i skog og beitemark') but fail to cover pristine mires. To generate a soil map for Norwegian mires, we emphasize the need for contemporary national data for ground-truthing remote sensing modelling methods. At this end, we recommend a onetime intensive sampling campaign (carbon, nitrogen and basic soil physical parameters with vertical and horizontal distribution along with peat depth measurements) for main mire types in Norway to generate a database that can be used to calibrate results from less intensive campaigns with larger geographic coverage. The generated data should be maintained in open access databases.   Estimated costs to generate a national soil map for peatlands are following:   1. Intensive data collection from selected mires to calculate carbon stocks  2. Extensive collection of peat depth data with large national coverage  3. Modelling the soil map  Costs related to point 1 are 1\,450\,000 kr for sampling of selected 30 mires. These costs include personnel and analysis costs but exclude travel costs. Inclusion of nitrogen analysis will increase the cost estimate by 500\,000 kr.   We also recommend that soil depth measurements are included in ongoing soil monitoring programs on peatlands, which have broad national coverage (e.g., ANO). Costs related to point 2. are 75 000 kr per year (coordination, planning and data-analysis), and added field sampling costs of 15\,000 - 30\,000 kr (without travel costs) per ANO -- location. Price per ANO-location varies depending on size and depth of mires at the location. Adding soil sampling (for better recording of carbon stocks) will increase prices per ANO- location by an estimated 10\,000 kr.   Costs related to point 3. remote sense modelling of soil carbon content in 3-5 years are estimated to be 800\,000 kr -- 1\,200\,000 kr, assuming that data collection presented in points 1 and 2 are carried out.\,   Current methodology for measuring peat depth (the most critical parameter to quantify soil carbon stocks) is laborious and time consuming. Various methods including landscape modelling and remote sensing are being tested and developed internationally. Building up competence and incorporating such techniques in Norway would significantly expedite developing a comprehensive map for soil carbon stocks in Norwegian mires.},
  copyright = {{\copyright} Norwegian Institute for Nature Research. The publication may be freely cited where the source is acknowledged},
  langid = {nob},
  keywords = {carbon,Norway,peatland,pedometrics,soil},
  annotation = {Accepted: 2023-12-01T15:35:21Z},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Silvennoinen et al. - 2023 - Roadmap for generating a soil map for Norwegian pr.pdf}
}

@article{sorensenCalculationTopographicWetness2006,
  title = {On the Calculation of the Topographic Wetness Index: Evaluation of Different Methods Based on Field Observations},
  shorttitle = {On the Calculation of the Topographic Wetness Index},
  author = {S{\o}rensen, R. and Zinko, U. and Seibert, J.},
  year = {2006},
  month = feb,
  journal = {Hydrology and Earth System Sciences},
  volume = {10},
  number = {1},
  pages = {101--112},
  publisher = {Copernicus GmbH},
  issn = {1027-5606},
  doi = {10.5194/hess-10-101-2006},
  urldate = {2024-04-11},
  abstract = {The topographic wetness index (TWI, ln(a/tan\&beta;)), which combines local upslope contributing area and slope, is commonly used to quantify topographic control on hydrological processes. Methods of computing this index differ primarily in the way the upslope contributing area is calculated. In this study we compared a number of calculation methods for TWI and evaluated them in terms of their correlation with the following measured variables: vascular plant species richness, soil pH, groundwater level, soil moisture, and a constructed wetness degree. The TWI was calculated by varying six parameters affecting the distribution of accumulated area among downslope cells and by varying the way the slope was calculated. All possible combinations of these parameters were calculated for two separate boreal forest sites in northern Sweden. We did not find a calculation method that performed best for all measured variables; rather the best methods seemed to be variable and site specific. However, we were able to identify some general characteristics of the best methods for different groups of measured variables. The results provide guiding principles for choosing the best method for estimating species richness, soil pH, groundwater level, and soil moisture by the TWI derived from digital elevation models.},
  langid = {english},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Sørensen et al. - 2006 - On the calculation of the topographic wetness inde.pdf}
}

@article{southeeApplicationLidarTerrain2012,
  title = {Application of {{Lidar Terrain Surfaces}} for {{Soil Moisture Modeling}}},
  author = {Southee, Florence Margaret and Treitz, Paul M. and Scott, Neal A.},
  year = {2012},
  month = dec,
  journal = {Photogrammetric Engineering \& Remote Sensing},
  volume = {78},
  number = {12},
  pages = {1241--1251},
  doi = {10.14358/PERS.78.11.1241},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Southee et al. - 2012 - Application of Lidar Terrain Surfaces for Soil Moi.pdf}
}

@article{stockDataLeakageJeopardizes2023,
  title = {Data Leakage Jeopardizes Ecological Applications of Machine Learning},
  author = {Stock, Andy and Gregr, Edward J. and Chan, Kai M. A.},
  year = {2023},
  month = aug,
  journal = {Nature Ecology \& Evolution},
  pages = {1--3},
  publisher = {Nature Publishing Group},
  issn = {2397-334X},
  doi = {10.1038/s41559-023-02162-1},
  urldate = {2023-08-15},
  abstract = {Machine learning is a popular tool in ecology but many scientific applications suffer from data leakage, causing misleading results. We highlight common pitfalls in ecological machine-learning methods and argue that discipline-specific model info sheets must be developed to aid in model evaluations.},
  copyright = {2023 Springer Nature Limited},
  langid = {english},
  keywords = {Ecological modelling,Environmental sciences,Ocean sciences}
}

@article{stockSpatiotemporalDistributionLabeled2022,
  title = {Spatiotemporal Distribution of Labeled Data Can Bias the Validation and Selection of Supervised Learning Algorithms: {{A}} Marine Remote Sensing Example},
  shorttitle = {Spatiotemporal Distribution of Labeled Data Can Bias the Validation and Selection of Supervised Learning Algorithms},
  author = {Stock, Andy},
  year = {2022},
  month = may,
  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  volume = {187},
  pages = {46--60},
  issn = {0924-2716},
  doi = {10.1016/j.isprsjprs.2022.02.023},
  urldate = {2023-08-15},
  abstract = {Supervised learning allows the prediction of variables measured in-situ from variables that can be measured from satellites. A labeled data set for this purpose is typically created by matching in-situ and satellite data and split into subsets for model training and initial validation. However, the available data are often not randomly distributed in space and time. In theory, this can bias estimates of prediction errors. Here, remote sensing of chlorophyll a in the Baltic Sea serves as an example to demonstrate the importance of this problem in marine remote sensing, and to test how well different statistical designs for validation mitigate it. Semi-synthetic data sets were created by combining daily chlorophyll a fields from a biogeochemical model hindcast with real-world locations and times of in-situ measurements, generated by sampling 2,000 combinations of cruises from an oceanographic database. These data sets were matched with co-located satellite data and used to train and validate four algorithms using remote sensing reflectances as input. The algorithms were validated using different methods including random hold-out sets and various block cross-validation designs based on geographical location, time, or location in predictor space. The resulting error estimates were compared to true errors calculated from differences to the biogeochemical model outputs serving as response variable. All validation methods underestimated prediction errors, in many cases by {$>$}30\%. While a simple band-ratio algorithm had the smallest true errors (e.g., absolute percentage difference: APD~=~50\%), estimated errors were smallest for more complicated and in fact less accurate machine learning algorithms. For example, ten-fold cross-validation led to selection of the truly best algorithm among four candidates for {$<$}10\% of data sets. The biases were smallest, but not absent, for spatial block cross-validation, which selected the truly best algorithm for 21--46\% of data sets, depending on the error measure. When the analyses were repeated with data that were randomly distributed in space and time, the biases of error estimates based on random splits became much smaller (e.g., 10-fold cross-validation estimated errors within 2\% of their true values and selected the truly best algorithm for {$>$}99\% of data sets), spatial block cross-validation overestimated prediction errors (often by {$>$}40\%), all algorithms achieved lower true errors, and a random forest made the most accurate predictions overall (APD~=~27\%). These results show that more attention should be paid to statistical methods for estimating the errors of supervised learning algorithms, e.g., by using multiple validation methods in combination and critically discussing error estimates considering questions of dependence, representativeness, and stationarity. Furthermore, non-random spatiotemporal distribution of labeled data can be a barrier to harnessing the full potential of machine learning algorithms in marine remote sensing.},
  keywords = {cross validation,ML,model complexity,model evaluation,model performance,To read,Validation},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Stock - 2022 - Spatiotemporal distribution of labeled data can bi.pdf}
}

@article{stroblBiasRandomForest2007,
  title = {Bias in Random Forest Variable Importance Measures: {{Illustrations}}, Sources and a Solution},
  shorttitle = {Bias in Random Forest Variable Importance Measures},
  author = {Strobl, Carolin and Boulesteix, Anne-Laure and Zeileis, Achim and Hothorn, Torsten},
  year = {2007},
  month = dec,
  journal = {BMC Bioinformatics},
  volume = {8},
  number = {1},
  pages = {25},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-8-25},
  urldate = {2024-08-27},
  copyright = {http://creativecommons.org/licenses/by/2.0},
  langid = {english},
  keywords = {random forest,variable importance},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Strobl et al. - 2007 - Bias in random forest variable importance measures.pdf}
}

@article{stroblConditionalVariableImportance2008,
  title = {Conditional Variable Importance for Random Forests},
  author = {Strobl, Carolin and Boulesteix, Anne-Laure and Kneib, Thomas and Augustin, Thomas and Zeileis, Achim},
  year = {2008},
  month = dec,
  journal = {BMC Bioinformatics},
  volume = {9},
  number = {1},
  pages = {307},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-9-307},
  urldate = {2024-08-27},
  abstract = {Background: Random forests are becoming increasingly popular in many scientific fields because they can cope with "small n large p" problems, complex interactions and even highly correlated predictor variables. Their variable importance measures have recently been suggested as screening tools for, e.g., gene expression studies. However, these variable importance measures show a bias towards correlated predictor variables. Results: We identify two mechanisms responsible for this finding: (i) A preference for the selection of correlated predictors in the tree building process and (ii) an additional advantage for correlated predictor variables induced by the unconditional permutation scheme that is employed in the computation of the variable importance measure. Based on these considerations we develop a new, conditional permutation scheme for the computation of the variable importance measure. Conclusion: The resulting conditional variable importance reflects the true impact of each predictor variable more reliably than the original marginal approach.},
  copyright = {http://creativecommons.org/licenses/by/2.0},
  langid = {english},
  keywords = {explainability,machine learning,multicollinearity,random forest,variable importance},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Strobl et al. - 2008 - Conditional variable importance for random forests.pdf}
}

@article{stumpfIncorporatingLimitedField2016,
  title = {Incorporating Limited Field Operability and Legacy Soil Samples in a Hypercube Sampling Design for Digital Soil Mapping},
  author = {Stumpf, Felix and Schmidt, Karsten and Behrens, Thorsten and {Sch{\"o}nbrodt-Stitt}, Sarah and Buzzo, Giovanni and Dumperth, Christian and Wadoux, Alexandre and Xiang, Wei and Scholten, Thomas},
  year = {2016},
  journal = {Journal of Plant Nutrition and Soil Science},
  volume = {179},
  number = {4},
  pages = {499--509},
  issn = {1522-2624},
  doi = {10.1002/jpln.201500313},
  urldate = {2023-06-21},
  abstract = {Most calibration sampling designs for Digital Soil Mapping (DSM) demarcate spatially distinct sample sites. In practical applications major challenges are often limited field accessibility and the question on how to integrate legacy soil samples to cope with usually scarce resources for field sampling and laboratory analysis. The study focuses on the development and application of an efficiency improved DSM sampling design that (1) applies an optimized sample set size, (2) compensates for limited field accessibility, and (3) enables the integration of legacy soil samples. The proposed sampling design represents a modification of conditioned Latin Hypercube Sampling (cLHS), which originally returns distinct sample sites to optimally cover a soil related covariate space and to preserve the correlation of the covariates in the sample set. The sample set size was determined by comparing multiple sample set sizes of original cLHS sets according to their representation of the covariate space. Limited field accessibility and the integration of legacy samples were incorporated by providing alternative sample sites to replace the original cLHS sites. We applied the modified cLHS design (cLHSadapt) in a small catchment (4.2 km2) in Central China to model topsoil sand fractions using Random Forest regression (RF). For evaluating the proposed approach, we compared cLHSadapt with the original cLHS design (cLHSorig). With an optimized sample set size n = 30, the results show a similar representation of the cLHS covariate space between cLHSadapt and cLHSorig, while the correlation between the covariates is preserved (r = 0.40 vs. r = 0.39). Furthermore, we doubled the sample set size of cLHSadapt by adding available legacy samples (cLHSadapt+) and compared the prediction accuracies. Based on an external validation set cLHSval (n = 20), the coefficient of determination (R2) of the cLHSadapt predictions range between 0.59 and 0.71 for topsoil sand fractions. The R2-values of the RF predictions based on cLHSadapt+, using additional legacy samples, are marginally increased on average by 5\%.},
  copyright = {Copyright {\copyright} 2016 WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim},
  langid = {english},
  keywords = {conditioned Latin Hypercube Sampling,digital soil mapping,field accessibility,fieldwork,legacy soil samples,random forest,sample set size},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Stumpf et al. - 2016 - Incorporating limited field operability and legacy.pdf}
}

@article{valaviBlockCVPackageGenerating2019,
  title = {{{blockCV}}: {{An}} r Package for Generating Spatially or Environmentally Separated Folds for k-Fold Cross-Validation of Species Distribution Models},
  shorttitle = {{{blockCV}}},
  author = {Valavi, Roozbeh and Elith, Jane and Lahoz-Monfort, Jos{\'e} J. and Guillera-Arroita, Gurutzeta},
  year = {2019},
  journal = {Methods in Ecology and Evolution},
  volume = {10},
  number = {2},
  pages = {225--232},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.13107},
  urldate = {2019-03-27},
  abstract = {When applied to structured data, conventional random cross-validation techniques can lead to underestimation of prediction error, and may result in inappropriate model selection. We present the r package blockCV, a new toolbox for cross-validation of species distribution modelling. Although it has been developed with species distribution modelling in mind, it can be used for any spatial modelling. The package can generate spatially or environmentally separated folds. It includes tools to measure spatial autocorrelation ranges in candidate covariates, providing the user with insights into the spatial structure in these data. It also offers interactive graphical capabilities for creating spatial blocks and exploring data folds. Package blockCV enables modellers to more easily implement a range of evaluation approaches. It will help the modelling community learn more about the impacts of evaluation approaches on our understanding of predictive performance of species distribution models.},
  copyright = {{\copyright} 2018 The Authors. Methods in Ecology and Evolution {\copyright} 2018 British Ecological Society},
  langid = {english},
  keywords = {autocorrelation,cross validation,model validation,R package,SDM},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Valavi et al_2019_blockCV.pdf}
}

@article{wadouxSamplingDesignOptimization2019,
  title = {Sampling Design Optimization for Soil Mapping with Random Forest},
  author = {Wadoux, Alexandre M. J-C. and Brus, Dick J. and Heuvelink, Gerard B. M.},
  year = {2019},
  month = dec,
  journal = {Geoderma},
  volume = {355},
  pages = {113913},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2019.113913},
  urldate = {2023-05-09},
  abstract = {Machine learning techniques are widely employed to generate digital soil maps. The map accuracy is partly determined by the number and spatial locations of the measurements used to calibrate the machine learning model. However, determining the optimal sampling design for mapping with machine learning techniques has not yet been considered in detail in digital soil mapping studies. In this paper, we investigate sampling design optimization for soil mapping with random forest. A design is optimized using spatial simulated annealing by minimizing the mean squared prediction error (MSE). We applied this approach to mapping soil organic carbon for a part of Europe using subsamples of the LUCAS dataset. The optimized subsamples are used as input for the random forest machine learning model, using a large set of readily available environmental data as covariates. We also predicted the same soil property using subsamples selected by simple random sampling, conditioned Latin Hypercube sampling (cLHS), spatial coverage sampling and feature space coverage sampling. Distributions of the estimated population MSEs are obtained through repeated random splitting of the LUCAS dataset, serving as the population of interest, into subsets used for validation, testing and selection of calibration samples, and repeated selection of calibration samples with the various sampling designs. The differences between the medians of the MSE distributions were tested for significance using the non-parametric Mann-Whitney test. The process was repeated for different sample sizes. We also analyzed the spread of the optimized designs in both geographic and feature space to reveal their characteristics. Results show that optimization of the sampling design by minimizing the MSE is worthwhile for small sample sizes. However, an important disadvantage of sampling design optimization using MSE is that it requires known values of the soil property at all locations and as a consequence is only feasible for subsampling an existing dataset. For larger sample sizes, the effect of using an MSE optimized design diminishes. In this case, we recommend to use a sample spread uniformly in the feature (i.e. covariate) space of the most important random forest covariates. The results also show that for our case study, cLHS sampling performs worse than the other sampling designs for mapping with random forest. We stress that comparison of sampling designs for calibration by splitting the data just once is very sensitive to the data split that one happens to use if the validation set is small.},
  langid = {english},
  keywords = {Conditioned Latin Hypercube,K-means,LUCAS,Optimal design,Pedometrics,Random forest,sampling design,Spatial coverage,Spatial simulated annealing,Uncertainty assessment},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Wadoux et al. - 2019 - Sampling design optimization for soil mapping with.pdf}
}

@article{wadouxSpatialCrossvalidationNot2021,
  title = {Spatial Cross-Validation Is Not the Right Way to Evaluate Map Accuracy},
  author = {Wadoux, Alexandre M. J. -C. and Heuvelink, Gerard B. M. and {de Bruin}, Sytze and Brus, Dick J.},
  year = {2021},
  month = oct,
  journal = {Ecological Modelling},
  volume = {457},
  pages = {109692},
  issn = {0304-3800},
  doi = {10.1016/j.ecolmodel.2021.109692},
  urldate = {2024-04-18},
  abstract = {For decades scientists have produced maps of biological, ecological and environmental variables. These studies commonly evaluate the map accuracy through cross-validation with the data used for calibrating the underlying mapping model. Recent studies, however, have argued that cross-validation statistics of most mapping studies are optimistically biased. They attribute these overoptimistic results to a supposed serious methodological flaw in standard cross-validation methods, namely that these methods ignore spatial autocorrelation in the data. They argue that spatial cross-validation should be used instead, and contend that standard cross-validation methods are inherently invalid in a geospatial context because of the autocorrelation present in most spatial data. Here we argue that these studies propagate a widespread misconception of statistical validation of maps. We explain that unbiased estimates of map accuracy indices can be obtained by probability sampling and design-based inference and illustrate this with a numerical experiment on large-scale above-ground biomass mapping. In our experiment, standard cross-validation (i.e., ignoring autocorrelation) led to smaller bias than spatial cross-validation. Standard cross-validation was deficient in case of a strongly clustered dataset that had large differences in sampling density, but less so than spatial cross-validation. We conclude that spatial cross-validation methods have no theoretical underpinning and should not be used for assessing map accuracy, while standard cross-validation is deficient in case of clustered data. Model-free, design-unbiased and valid accuracy assessment is achieved with probability sampling and design-based inference. It is valid without the need to explicitly incorporate or adjust for spatial autocorrelation and perfectly suited for the validation of large scale biological, ecological and environmental maps.},
  keywords = {Above-ground biomass,Design-based,Design-unbiased,Map quality,Model performance,Model-based,Random forest,Sampling theory},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Wadoux et al. - 2021 - Spatial cross-validation is not the right way to e.pdf}
}

@article{wangSpatialNewCrossvalidation2023,
  title = {Spatial+: {{A}} New Cross-Validation Method to Evaluate Geospatial Machine Learning Models},
  shorttitle = {Spatial+},
  author = {Wang, Yanwen and Khodadadzadeh, Mahdi and {Zurita-Milla}, Ra{\'u}l},
  year = {2023},
  month = jul,
  journal = {International Journal of Applied Earth Observation and Geoinformation},
  volume = {121},
  pages = {103364},
  issn = {1569-8432},
  doi = {10.1016/j.jag.2023.103364},
  urldate = {2024-08-16},
  abstract = {Random cross-validation (CV) is often used to evaluate geospatial machine learning models, particularly when a limited amount of sample data are available, and collecting an extra test set is unfeasible. However, the prediction locations can be substantially different from the available sample, leading to over-optimistic evaluation results. This has fostered the development of spatial CV methods. Yet these methods only focus on spatial autocorrelation and cannot sufficiently guarantee that the validation subset is a good proxy of the test set with significant differences. In this paper, we propose the spatial+ cross-validation (SP-CV) method. This method, which considers both the geographic and feature spaces, is composed of two stages. The first stage addresses spatial autocorrelation issues by using agglomerative hierarchical clustering to divide the available sample into blocks. The second stage deals with multiple sources of differences. It uses cluster ensembles to split the blocks into training and validation folds based on the locations of the sample data and the values of the covariates and target variable. The proposed method is compared against random and block CV methods in a series of experiments with Amazon basin above ground biomass and California houseprice datasets. Our results show that SP-CV provided the smallest error differences with respect to the reference error. This means that SP-CV produced more representative splits and led to more reliable model evaluations. It suggests that a reliable model evaluation requires to consider both the geographic and the feature spaces in a comprehensive manner.},
  keywords = {Cross-validation,Data-driven models,Feature space,Model evaluation,Spatial autocorrelation},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Wang et al. - 2023 - Spatial+ A new cross-validation method to evaluat.pdf}
}

@techreport{wisenE39Romsdalsfjorden202020212021,
  title = {E39 {{Romsdalsfjorden}} 2020-2021 {{Georadarunders{\o}kelse {\O}rskogfjellet-Vik}}},
  author = {Wis{\'e}n, Roger},
  year = {2021},
  month = nov,
  institution = {Impakt geofysikk},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Wisén - 2021 - E39 Romsdalsfjorden 2020-2021 Georadarundersøkelse.pdf}
}

@techreport{wisenE39Romsdalsfjorden20212021,
  title = {E39 {{Romsdalsfjorden}} 2021 {{Georadarunders{\o}kelse Digernes-{\O}rskogfjellet}}},
  author = {Wis{\'e}n, Roger},
  year = {2021},
  month = nov,
  institution = {Impakt geofysikk},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Wisén - 2021 - E39 Romsdalsfjorden 2021 Georadarundersøkelse Dige.pdf}
}

@article{wrightRangerFastImplementation2017,
  title = {Ranger: {{A Fast Implementation}} of {{Random Forests}} for {{High Dimensional Data}} in {{C}}++ and {{R}}},
  shorttitle = {Ranger},
  author = {Wright, Marvin N. and Ziegler, Andreas},
  year = {2017},
  month = mar,
  journal = {Journal of Statistical Software},
  volume = {77},
  pages = {1--17},
  issn = {1548-7660},
  doi = {10.18637/jss.v077.i01},
  urldate = {2024-04-09},
  abstract = {We introduce the C++ application and R package ranger. The software is a fast implementation of random forests for high dimensional data. Ensembles of classification, regression and survival trees are supported. We describe the implementation, provide examples, validate the package with a reference implementation, and compare runtime and memory usage with other implementations. The new software proves to scale best with the number of features, samples, trees, and features tried for splitting. Finally, we show that ranger is the fastest and most memory efficient implementation of random forests to analyze data on the scale of a genome-wide association study.},
  copyright = {Copyright (c) 2017 Marvin N. Wright, Andreas Ziegler},
  langid = {english},
  keywords = {C,classification,machine learning,R,random forests,Rcpp,recursive partitioning,survival analysis},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Wright and Ziegler - 2017 - ranger A Fast Implementation of Random Forests fo.pdf}
}

@article{yatesCrossValidationModel2023,
  title = {Cross Validation for Model Selection: {{A}} Review with Examples from Ecology},
  shorttitle = {Cross Validation for Model Selection},
  author = {Yates, Luke A. and Aandahl, Zach and Richards, Shane A. and Brook, Barry W.},
  year = {2023},
  journal = {Ecological Monographs},
  volume = {93},
  number = {1},
  pages = {e1557},
  issn = {1557-7015},
  doi = {10.1002/ecm.1557},
  urldate = {2023-04-11},
  abstract = {Specifying, assessing, and selecting among candidate statistical models is fundamental to ecological research. Commonly used approaches to model selection are based on predictive scores and include information criteria such as Akaike's information criterion, and cross validation. Based on data splitting, cross validation is particularly versatile because it can be used even when it is not possible to derive a likelihood (e.g., many forms of machine learning) or count parameters precisely (e.g., mixed-effects models). However, much of the literature on cross validation is technical and spread across statistical journals, making it difficult for ecological analysts to assess and choose among the wide range of options. Here we provide a comprehensive, accessible review that explains important---but often overlooked---technical aspects of cross validation for model selection, such as: bias correction, estimation uncertainty, choice of scores, and selection rules to mitigate overfitting. We synthesize the relevant statistical advances to make recommendations for the choice of cross-validation technique and we present two ecological case studies to illustrate their application. In most instances, we recommend using exact or approximate leave-one-out cross validation to minimize bias, or otherwise k-fold with bias correction if k {$<$} 10. To mitigate overfitting when using cross validation, we recommend calibrated selection via our recently introduced modified one-standard-error rule. We advocate for the use of predictive scores in model selection across a range of typical modeling goals, such as exploration, hypothesis testing, and prediction, provided that models are specified in accordance with the stated goal. We also emphasize, as others have done, that inference on parameter estimates is biased if preceded by model selection and instead requires a carefully specified single model or further technical adjustments.},
  langid = {english},
  keywords = {cross validation,information theory,model complexity,model selection,overfitting,parsimony,post-selection inference,review,statistics},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Yates et al. - 2023 - Cross validation for model selection A review wit.pdf}
}

@article{yuanDeepLearningEnvironmental2020,
  title = {Deep Learning in Environmental Remote Sensing: {{Achievements}} and Challenges},
  shorttitle = {Deep Learning in Environmental Remote Sensing},
  author = {Yuan, Qiangqiang and Shen, Huanfeng and Li, Tongwen and Li, Zhiwei and Li, Shuwen and Jiang, Yun and Xu, Hongzhang and Tan, Weiwei and Yang, Qianqian and Wang, Jiwen and Gao, Jianhao and Zhang, Liangpei},
  year = {2020},
  month = may,
  journal = {Remote Sensing of Environment},
  volume = {241},
  pages = {111716},
  issn = {0034-4257},
  doi = {10.1016/j.rse.2020.111716},
  urldate = {2023-05-24},
  abstract = {Various forms of machine learning (ML) methods have historically played a valuable role in environmental remote sensing research. With an increasing amount of ``big data'' from earth observation and rapid advances in ML, increasing opportunities for novel methods have emerged to aid in earth environmental monitoring. Over the last decade, a typical and state-of-the-art ML framework named deep learning (DL), which is developed from the traditional neural network (NN), has outperformed traditional models with considerable improvement in performance. Substantial progress in developing a DL methodology for a variety of earth science applications has been observed. Therefore, this review will concentrate on the use of the traditional NN and DL methods to advance the environmental remote sensing process. First, the potential of DL in environmental remote sensing, including land cover mapping, environmental parameter retrieval, data fusion and downscaling, and information reconstruction and prediction, will be analyzed. A typical network structure will then be introduced. Afterward, the applications of DL environmental monitoring in the atmosphere, vegetation, hydrology, air and land surface temperature, evapotranspiration, solar radiation, and ocean color are specifically reviewed. Finally, challenges and future perspectives will be comprehensively analyzed and discussed.},
  langid = {english},
  keywords = {deep learning,ML,NN,remote sensing},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Yuan et al. - 2020 - Deep learning in environmental remote sensing Ach.pdf}
}

@article{zhangApplicationGeneralizedLinear2023,
  title = {Application of Generalized Linear Geostatistical Model for Regional Soil Organic Matter Mapping: {{The}} Effect of Sampling Density},
  shorttitle = {Application of Generalized Linear Geostatistical Model for Regional Soil Organic Matter Mapping},
  author = {Zhang, Mei-Wei and Hao, Chenkai and Wang, Xiaoqing and Sun, Xiao-Lin},
  year = {2023},
  month = may,
  journal = {Geoderma},
  volume = {433},
  pages = {116446},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2023.116446},
  urldate = {2023-04-11},
  abstract = {The generalized linear geostatistical model (GLGM) is a formal approach of regression kriging that would be advantageous over commonly used modelling approaches for digital soil mapping (DSM). However, it has not been well explored in the literature, due to heavy computation. This study evaluates such formal approach for mapping soil organic matter at a regional scale (179,700~km2). We hypothesized that GLGM would be a better approach than other approaches as it can model nonlinear relationships and spatially consider the residuals. However, the accuracy would depend on sampling density. We compared GLGM with multiple linear regression (MLR), ordinary kriging (OK), regression kriging (RK), random forest (RF), generalized linear mixture model (GLMM), and generalized additive model (GAM). The effect of sampling density on the performance was also investigated by fitting the models based on resampling the samples with a series of sizes ranging from 100 to 1200. Results showed that GLGM generally improved the accuracy of DSM, compared with MLR, OK, RF, GLMM, and GAM, especially for large sample sizes, although the improvement was not significant. In a few cases, GLGM outperformed RK. The GLGM modelling and its prediction were largely influenced by sampling densities. Given small sample sizes, GLGM was unstable and the parameters were highly variable depending on the modelling realizations. Other influencing factors include linear and smooth correlations between soil and environmental covariates, spatial autocorrelation of the residuals, compatibility of spatial scales of soil samples and environmental covariates, and the scale of soil variation. For these factors, researchers with a more dense soil sampling are needed in future to explore the benefits of GLGM as a hybrid model for spatial prediction of soil.},
  langid = {english},
  keywords = {digital soil mapping,Digital soil mapping,GAM,Generalized linear geostatistical model,geostatistics,GLMM,kriging,organic matter,Pedometrics,regression kriging,RF,SAC,Sampling density},
  file = {C:\Users\julienv\OneDrive - Høgskulen på Vestlandet\ZoteroLibrary\Zhang et al. - 2023 - Application of generalized linear geostatistical m.pdf}
}
